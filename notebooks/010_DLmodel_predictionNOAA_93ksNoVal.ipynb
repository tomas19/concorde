{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tacuevas/miniconda3/envs/tf2/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "2024-01-19 09:34:24.172306: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-19 09:34:25.160711: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/tacuevas/miniconda3/envs/tf2/lib/\n",
      "2024-01-19 09:34:25.160847: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/tacuevas/miniconda3/envs/tf2/lib/\n",
      "2024-01-19 09:34:25.160857: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, BatchNormalization, Dropout, Masking\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "import tensorflow.keras.backend as K\n",
    "import time\n",
    "\n",
    "# %%\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# %%\n",
    "#### Change inputs\n",
    "modelID = '93ks'\n",
    "## noaa stations following same order of the outputs\n",
    "NOAAstations = ['Duck', 'Oregon', 'Hatteras', 'Beaufort', 'Wilmington', 'Wrightsville', 'Albemarle', 'Pamlico', 'Neuse']\n",
    "\n",
    "#### Define paths and load data\n",
    "# pathData = Path(r'../../../data/random_split')\n",
    "pathData = Path(r'/mnt/drive1/Insyncs/NCSU/thesis/models/NNmodel/inputs/random_split')\n",
    "# pathColSample = pathData.parent\n",
    "pathColSample = Path(r'/mnt/drive1/Insyncs/NCSU/thesis/models/adcirc/concorde/batch02/_postprocessing/_preprocessForNN')\n",
    "X_train_file = 'X_train_standardScaled_allInputs_augmentedAllX50_ALL.npy'\n",
    "Y_train_file = 'y_train_augmentedAllX50_ALL.npy'\n",
    "X_test_file = 'X_test_standardScaled_allInputs_augmentedAllX50_ALL.npy'\n",
    "Y_test_file = 'y_test_augmentedAllX50_ALL.npy'\n",
    "\n",
    "#### some hyperparameters\n",
    "batch_size = 100\n",
    "epochs = 950\n",
    "fold = 1 ## no cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### path to store outputs\n",
    "#pathOut0 = Path(r'/mnt/drive1/Insyncs/NCSU/thesis/models/NNmodel/81')\n",
    "pathOut = Path(f'../models/NNmodel/1DCNN_final_architecture/fftAndOffshoreTides/{modelID}')\n",
    "#pathOut0 = pathOut0/st\n",
    "\n",
    "#### class to save best model\n",
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, pathout, fold, modelID):\n",
    "        super(CustomCallback, self).__init__()\n",
    "        self.pathout = pathout\n",
    "        self.fold = fold\n",
    "        self.modelID = modelID\n",
    "        self.previous_val_loss = float('inf')  # Initialize with a high value\n",
    "        self.best_epoch = None\n",
    "        self.best_model = None\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current_val_loss = logs.get('val_loss')\n",
    "        if current_val_loss is not None and current_val_loss < self.previous_val_loss:\n",
    "            self.model.save(self.pathout / f'bestModel_{self.modelID}_noVal.tf')\n",
    "            self.previous_val_loss = current_val_loss\n",
    "            self.best_epoch = epoch\n",
    "            self.best_model = self.model\n",
    "            with open(self.pathout / f'best_model_noVal.txt', 'a') as fout:\n",
    "                fout.write(f'Best model saved for fold {self.fold}: epoch {self.best_epoch}, val_loss: {current_val_loss:0.3f}\\n')\n",
    "\n",
    "#### load data\n",
    "X_train = np.load(pathData/X_train_file)\n",
    "y_train = np.load(pathData/Y_train_file)\n",
    "X_test = np.load(pathData/X_test_file)\n",
    "y_test = np.load(pathData/Y_test_file)\n",
    "\n",
    "#### pathout\n",
    "#pathOut = pathOut0/st\n",
    "\n",
    "columns_sample = pd.read_csv(pathColSample/'dct_tracksAll_batch02_ALL_lengthCorr_tides_resampled_SAMPLE.csv', index_col = 0)\n",
    "\n",
    "## inputs\n",
    "cols = ['wind_speed', 'pressure', 'rad_to_max_ws', 'forward_speed_u', 'forward_speed_v',\n",
    "        'wind_speed_fft', 'pressure_fft', 'rad_to_max_ws_fft', 'forward_speed_u_fft', 'forward_speed_v_fft',\n",
    "            'dist_to_duck', 'dist_to_oregon', 'dist_to_hatteras', 'dist_to_beaufort', 'dist_to_wilmington', \n",
    "            'dist_to_wrightsville', 'dist_to_Albemarle', 'dist_to_Pamlico', 'dist_to_Neuse', 'Boundary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## extract inputs idx from the full input array\n",
    "idx_cols = [list(columns_sample).index(x) for x in cols]\n",
    "X_train = X_train[:, :, idx_cols]\n",
    "X_test = X_test[:, :, idx_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking (Masking)           (None, 235, 20)           0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 233, 16)           976       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 233, 16)          64        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 116, 16)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 114, 32)           1568      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 114, 32)          128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 57, 32)           0         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-19 09:34:34.128574: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-19 09:34:35.451338: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4356 MB memory:  -> device: 0, name: Quadro P2000, pci bus id: 0000:5b:00.0, compute capability: 6.1\n",
      "2024-01-19 09:34:35.452235: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 3588 MB memory:  -> device: 1, name: Quadro P2000, pci bus id: 0000:9e:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 55, 64)            6208      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 55, 64)           256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 27, 64)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1728)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                110656    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 9)                 297       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122,233\n",
      "Trainable params: 122,009\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n",
      "Epoch 1/950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-19 09:34:42.119422: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2024-01-19 09:34:42.952093: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-01-19 09:34:43.818635: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f0ee800cfb0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-01-19 09:34:43.818726: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): Quadro P2000, Compute Capability 6.1\n",
      "2024-01-19 09:34:43.818751: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): Quadro P2000, Compute Capability 6.1\n",
      "2024-01-19 09:34:43.849450: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-01-19 09:34:44.045371: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-01-19 09:34:44.106766: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "786/786 [==============================] - 22s 19ms/step - loss: 0.2414 - mse: 0.5734 - mae: 0.5435 - rmse: 0.7572\n",
      "Epoch 2/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.1682 - mse: 0.3766 - mae: 0.4378 - rmse: 0.6137\n",
      "Epoch 3/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.1376 - mse: 0.3005 - mae: 0.3896 - rmse: 0.5482\n",
      "Epoch 4/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.1173 - mse: 0.2534 - mae: 0.3554 - rmse: 0.5034\n",
      "Epoch 5/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.1019 - mse: 0.2178 - mae: 0.3288 - rmse: 0.4667\n",
      "Epoch 6/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0909 - mse: 0.1928 - mae: 0.3081 - rmse: 0.4391\n",
      "Epoch 7/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0823 - mse: 0.1734 - mae: 0.2914 - rmse: 0.4164\n",
      "Epoch 8/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0759 - mse: 0.1590 - mae: 0.2787 - rmse: 0.3988\n",
      "Epoch 9/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0705 - mse: 0.1470 - mae: 0.2684 - rmse: 0.3834\n",
      "Epoch 10/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0667 - mse: 0.1383 - mae: 0.2607 - rmse: 0.3719\n",
      "Epoch 11/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0638 - mse: 0.1322 - mae: 0.2548 - rmse: 0.3637\n",
      "Epoch 12/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0614 - mse: 0.1270 - mae: 0.2496 - rmse: 0.3564\n",
      "Epoch 13/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0590 - mse: 0.1215 - mae: 0.2448 - rmse: 0.3485\n",
      "Epoch 14/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0575 - mse: 0.1185 - mae: 0.2413 - rmse: 0.3442\n",
      "Epoch 15/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0555 - mse: 0.1141 - mae: 0.2376 - rmse: 0.3378\n",
      "Epoch 16/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0543 - mse: 0.1116 - mae: 0.2345 - rmse: 0.3340\n",
      "Epoch 17/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0531 - mse: 0.1088 - mae: 0.2319 - rmse: 0.3299\n",
      "Epoch 18/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0518 - mse: 0.1060 - mae: 0.2294 - rmse: 0.3256\n",
      "Epoch 19/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0509 - mse: 0.1042 - mae: 0.2272 - rmse: 0.3229\n",
      "Epoch 20/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0500 - mse: 0.1022 - mae: 0.2253 - rmse: 0.3197\n",
      "Epoch 21/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0490 - mse: 0.1000 - mae: 0.2230 - rmse: 0.3163\n",
      "Epoch 22/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0483 - mse: 0.0985 - mae: 0.2215 - rmse: 0.3138\n",
      "Epoch 23/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0478 - mse: 0.0974 - mae: 0.2203 - rmse: 0.3121\n",
      "Epoch 24/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0472 - mse: 0.0962 - mae: 0.2189 - rmse: 0.3101\n",
      "Epoch 25/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0465 - mse: 0.0948 - mae: 0.2174 - rmse: 0.3079\n",
      "Epoch 26/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0462 - mse: 0.0940 - mae: 0.2168 - rmse: 0.3066\n",
      "Epoch 27/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0454 - mse: 0.0924 - mae: 0.2149 - rmse: 0.3040\n",
      "Epoch 28/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0450 - mse: 0.0915 - mae: 0.2142 - rmse: 0.3025\n",
      "Epoch 29/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0446 - mse: 0.0907 - mae: 0.2129 - rmse: 0.3011\n",
      "Epoch 30/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0442 - mse: 0.0897 - mae: 0.2123 - rmse: 0.2996\n",
      "Epoch 31/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0440 - mse: 0.0895 - mae: 0.2117 - rmse: 0.2992\n",
      "Epoch 32/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0435 - mse: 0.0884 - mae: 0.2105 - rmse: 0.2972\n",
      "Epoch 33/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0432 - mse: 0.0877 - mae: 0.2099 - rmse: 0.2962\n",
      "Epoch 34/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0427 - mse: 0.0867 - mae: 0.2087 - rmse: 0.2944\n",
      "Epoch 35/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0423 - mse: 0.0859 - mae: 0.2084 - rmse: 0.2931\n",
      "Epoch 36/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0423 - mse: 0.0858 - mae: 0.2079 - rmse: 0.2929\n",
      "Epoch 37/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0421 - mse: 0.0855 - mae: 0.2074 - rmse: 0.2924\n",
      "Epoch 38/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0419 - mse: 0.0851 - mae: 0.2069 - rmse: 0.2916\n",
      "Epoch 39/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0414 - mse: 0.0841 - mae: 0.2060 - rmse: 0.2900\n",
      "Epoch 40/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0412 - mse: 0.0835 - mae: 0.2055 - rmse: 0.2890\n",
      "Epoch 41/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0410 - mse: 0.0830 - mae: 0.2050 - rmse: 0.2881\n",
      "Epoch 42/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0409 - mse: 0.0830 - mae: 0.2048 - rmse: 0.2882\n",
      "Epoch 43/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0406 - mse: 0.0822 - mae: 0.2039 - rmse: 0.2867\n",
      "Epoch 44/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0403 - mse: 0.0818 - mae: 0.2036 - rmse: 0.2859\n",
      "Epoch 45/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0401 - mse: 0.0813 - mae: 0.2030 - rmse: 0.2851\n",
      "Epoch 46/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0400 - mse: 0.0811 - mae: 0.2027 - rmse: 0.2847\n",
      "Epoch 47/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0398 - mse: 0.0806 - mae: 0.2023 - rmse: 0.2839\n",
      "Epoch 48/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0396 - mse: 0.0803 - mae: 0.2018 - rmse: 0.2834\n",
      "Epoch 49/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0395 - mse: 0.0802 - mae: 0.2015 - rmse: 0.2832\n",
      "Epoch 50/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0394 - mse: 0.0798 - mae: 0.2014 - rmse: 0.2826\n",
      "Epoch 51/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0392 - mse: 0.0796 - mae: 0.2006 - rmse: 0.2822\n",
      "Epoch 52/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0389 - mse: 0.0789 - mae: 0.2002 - rmse: 0.2808\n",
      "Epoch 53/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0390 - mse: 0.0791 - mae: 0.2002 - rmse: 0.2812\n",
      "Epoch 54/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0385 - mse: 0.0779 - mae: 0.1992 - rmse: 0.2790\n",
      "Epoch 55/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0385 - mse: 0.0779 - mae: 0.1991 - rmse: 0.2791\n",
      "Epoch 56/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0384 - mse: 0.0777 - mae: 0.1989 - rmse: 0.2787\n",
      "Epoch 57/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0384 - mse: 0.0777 - mae: 0.1988 - rmse: 0.2787\n",
      "Epoch 58/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0381 - mse: 0.0771 - mae: 0.1982 - rmse: 0.2776\n",
      "Epoch 59/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0379 - mse: 0.0767 - mae: 0.1979 - rmse: 0.2770\n",
      "Epoch 60/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0380 - mse: 0.0771 - mae: 0.1978 - rmse: 0.2776\n",
      "Epoch 61/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0377 - mse: 0.0764 - mae: 0.1972 - rmse: 0.2764\n",
      "Epoch 62/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0376 - mse: 0.0761 - mae: 0.1971 - rmse: 0.2758\n",
      "Epoch 63/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0372 - mse: 0.0752 - mae: 0.1962 - rmse: 0.2742\n",
      "Epoch 64/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0375 - mse: 0.0759 - mae: 0.1969 - rmse: 0.2755\n",
      "Epoch 65/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0371 - mse: 0.0751 - mae: 0.1960 - rmse: 0.2740\n",
      "Epoch 66/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0371 - mse: 0.0750 - mae: 0.1957 - rmse: 0.2738\n",
      "Epoch 67/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0368 - mse: 0.0744 - mae: 0.1951 - rmse: 0.2728\n",
      "Epoch 68/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0366 - mse: 0.0740 - mae: 0.1948 - rmse: 0.2721\n",
      "Epoch 69/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0367 - mse: 0.0742 - mae: 0.1949 - rmse: 0.2725\n",
      "Epoch 70/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0364 - mse: 0.0736 - mae: 0.1944 - rmse: 0.2713\n",
      "Epoch 71/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0365 - mse: 0.0738 - mae: 0.1944 - rmse: 0.2717\n",
      "Epoch 72/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0364 - mse: 0.0736 - mae: 0.1941 - rmse: 0.2712\n",
      "Epoch 73/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0365 - mse: 0.0739 - mae: 0.1942 - rmse: 0.2718\n",
      "Epoch 74/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0363 - mse: 0.0735 - mae: 0.1941 - rmse: 0.2711\n",
      "Epoch 75/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0362 - mse: 0.0733 - mae: 0.1938 - rmse: 0.2707\n",
      "Epoch 76/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0359 - mse: 0.0727 - mae: 0.1931 - rmse: 0.2696\n",
      "Epoch 77/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0361 - mse: 0.0729 - mae: 0.1933 - rmse: 0.2701\n",
      "Epoch 78/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0358 - mse: 0.0724 - mae: 0.1929 - rmse: 0.2691\n",
      "Epoch 79/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0357 - mse: 0.0722 - mae: 0.1925 - rmse: 0.2687\n",
      "Epoch 80/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0357 - mse: 0.0722 - mae: 0.1925 - rmse: 0.2687\n",
      "Epoch 81/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0355 - mse: 0.0717 - mae: 0.1920 - rmse: 0.2677\n",
      "Epoch 82/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0356 - mse: 0.0721 - mae: 0.1923 - rmse: 0.2685\n",
      "Epoch 83/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0353 - mse: 0.0712 - mae: 0.1917 - rmse: 0.2669\n",
      "Epoch 84/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0354 - mse: 0.0717 - mae: 0.1917 - rmse: 0.2677\n",
      "Epoch 85/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0353 - mse: 0.0714 - mae: 0.1916 - rmse: 0.2672\n",
      "Epoch 86/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0352 - mse: 0.0712 - mae: 0.1912 - rmse: 0.2668\n",
      "Epoch 87/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0350 - mse: 0.0708 - mae: 0.1908 - rmse: 0.2661\n",
      "Epoch 88/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0351 - mse: 0.0709 - mae: 0.1908 - rmse: 0.2663\n",
      "Epoch 89/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0350 - mse: 0.0708 - mae: 0.1907 - rmse: 0.2660\n",
      "Epoch 90/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0348 - mse: 0.0704 - mae: 0.1903 - rmse: 0.2653\n",
      "Epoch 91/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0348 - mse: 0.0702 - mae: 0.1899 - rmse: 0.2650\n",
      "Epoch 92/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0346 - mse: 0.0700 - mae: 0.1898 - rmse: 0.2646\n",
      "Epoch 93/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0346 - mse: 0.0699 - mae: 0.1898 - rmse: 0.2643\n",
      "Epoch 94/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0343 - mse: 0.0693 - mae: 0.1889 - rmse: 0.2632\n",
      "Epoch 95/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0344 - mse: 0.0695 - mae: 0.1894 - rmse: 0.2637\n",
      "Epoch 96/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0346 - mse: 0.0700 - mae: 0.1896 - rmse: 0.2645\n",
      "Epoch 97/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0342 - mse: 0.0692 - mae: 0.1888 - rmse: 0.2630\n",
      "Epoch 98/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0341 - mse: 0.0689 - mae: 0.1885 - rmse: 0.2626\n",
      "Epoch 99/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0341 - mse: 0.0690 - mae: 0.1884 - rmse: 0.2627\n",
      "Epoch 100/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0340 - mse: 0.0687 - mae: 0.1881 - rmse: 0.2622\n",
      "Epoch 101/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0340 - mse: 0.0687 - mae: 0.1882 - rmse: 0.2621\n",
      "Epoch 102/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0341 - mse: 0.0689 - mae: 0.1884 - rmse: 0.2625\n",
      "Epoch 103/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0338 - mse: 0.0682 - mae: 0.1875 - rmse: 0.2612\n",
      "Epoch 104/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0337 - mse: 0.0681 - mae: 0.1875 - rmse: 0.2610\n",
      "Epoch 105/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0339 - mse: 0.0685 - mae: 0.1876 - rmse: 0.2618\n",
      "Epoch 106/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0337 - mse: 0.0681 - mae: 0.1875 - rmse: 0.2610\n",
      "Epoch 107/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0336 - mse: 0.0679 - mae: 0.1871 - rmse: 0.2605\n",
      "Epoch 108/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0334 - mse: 0.0673 - mae: 0.1866 - rmse: 0.2595\n",
      "Epoch 109/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0334 - mse: 0.0674 - mae: 0.1865 - rmse: 0.2596\n",
      "Epoch 110/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0334 - mse: 0.0676 - mae: 0.1867 - rmse: 0.2599\n",
      "Epoch 111/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0332 - mse: 0.0671 - mae: 0.1863 - rmse: 0.2591\n",
      "Epoch 112/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0333 - mse: 0.0672 - mae: 0.1862 - rmse: 0.2592\n",
      "Epoch 113/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0331 - mse: 0.0669 - mae: 0.1860 - rmse: 0.2587\n",
      "Epoch 114/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0332 - mse: 0.0670 - mae: 0.1861 - rmse: 0.2589\n",
      "Epoch 115/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0331 - mse: 0.0668 - mae: 0.1859 - rmse: 0.2585\n",
      "Epoch 116/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0329 - mse: 0.0665 - mae: 0.1856 - rmse: 0.2578\n",
      "Epoch 117/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0328 - mse: 0.0661 - mae: 0.1850 - rmse: 0.2572\n",
      "Epoch 118/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0329 - mse: 0.0664 - mae: 0.1852 - rmse: 0.2577\n",
      "Epoch 119/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0327 - mse: 0.0660 - mae: 0.1848 - rmse: 0.2569\n",
      "Epoch 120/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0328 - mse: 0.0662 - mae: 0.1850 - rmse: 0.2574\n",
      "Epoch 121/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0326 - mse: 0.0659 - mae: 0.1845 - rmse: 0.2566\n",
      "Epoch 122/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0326 - mse: 0.0658 - mae: 0.1844 - rmse: 0.2566\n",
      "Epoch 123/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0325 - mse: 0.0655 - mae: 0.1843 - rmse: 0.2559\n",
      "Epoch 124/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0324 - mse: 0.0654 - mae: 0.1840 - rmse: 0.2558\n",
      "Epoch 125/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0324 - mse: 0.0654 - mae: 0.1840 - rmse: 0.2558\n",
      "Epoch 126/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0324 - mse: 0.0653 - mae: 0.1840 - rmse: 0.2556\n",
      "Epoch 127/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0324 - mse: 0.0654 - mae: 0.1840 - rmse: 0.2558\n",
      "Epoch 128/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0322 - mse: 0.0650 - mae: 0.1834 - rmse: 0.2549\n",
      "Epoch 129/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0323 - mse: 0.0652 - mae: 0.1837 - rmse: 0.2554\n",
      "Epoch 130/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0319 - mse: 0.0644 - mae: 0.1829 - rmse: 0.2538\n",
      "Epoch 131/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0321 - mse: 0.0648 - mae: 0.1831 - rmse: 0.2546\n",
      "Epoch 132/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0321 - mse: 0.0648 - mae: 0.1830 - rmse: 0.2545\n",
      "Epoch 133/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0319 - mse: 0.0644 - mae: 0.1827 - rmse: 0.2538\n",
      "Epoch 134/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0318 - mse: 0.0642 - mae: 0.1823 - rmse: 0.2533\n",
      "Epoch 135/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0318 - mse: 0.0642 - mae: 0.1825 - rmse: 0.2534\n",
      "Epoch 136/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0317 - mse: 0.0640 - mae: 0.1821 - rmse: 0.2530\n",
      "Epoch 137/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0317 - mse: 0.0639 - mae: 0.1821 - rmse: 0.2528\n",
      "Epoch 138/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0316 - mse: 0.0638 - mae: 0.1819 - rmse: 0.2527\n",
      "Epoch 139/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0316 - mse: 0.0637 - mae: 0.1819 - rmse: 0.2524\n",
      "Epoch 140/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0315 - mse: 0.0637 - mae: 0.1817 - rmse: 0.2523\n",
      "Epoch 141/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0315 - mse: 0.0636 - mae: 0.1815 - rmse: 0.2522\n",
      "Epoch 142/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0315 - mse: 0.0635 - mae: 0.1815 - rmse: 0.2519\n",
      "Epoch 143/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0315 - mse: 0.0637 - mae: 0.1815 - rmse: 0.2523\n",
      "Epoch 144/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0314 - mse: 0.0634 - mae: 0.1814 - rmse: 0.2518\n",
      "Epoch 145/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0314 - mse: 0.0633 - mae: 0.1811 - rmse: 0.2517\n",
      "Epoch 146/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0313 - mse: 0.0632 - mae: 0.1812 - rmse: 0.2514\n",
      "Epoch 147/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0312 - mse: 0.0630 - mae: 0.1809 - rmse: 0.2510\n",
      "Epoch 148/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0313 - mse: 0.0631 - mae: 0.1807 - rmse: 0.2512\n",
      "Epoch 149/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0312 - mse: 0.0630 - mae: 0.1806 - rmse: 0.2510\n",
      "Epoch 150/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0312 - mse: 0.0630 - mae: 0.1807 - rmse: 0.2511\n",
      "Epoch 151/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0312 - mse: 0.0629 - mae: 0.1805 - rmse: 0.2508\n",
      "Epoch 152/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0312 - mse: 0.0630 - mae: 0.1805 - rmse: 0.2509\n",
      "Epoch 153/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0309 - mse: 0.0624 - mae: 0.1798 - rmse: 0.2497\n",
      "Epoch 154/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0309 - mse: 0.0622 - mae: 0.1797 - rmse: 0.2495\n",
      "Epoch 155/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0309 - mse: 0.0623 - mae: 0.1797 - rmse: 0.2495\n",
      "Epoch 156/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0309 - mse: 0.0624 - mae: 0.1799 - rmse: 0.2498\n",
      "Epoch 157/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0309 - mse: 0.0623 - mae: 0.1797 - rmse: 0.2496\n",
      "Epoch 158/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0308 - mse: 0.0621 - mae: 0.1793 - rmse: 0.2493\n",
      "Epoch 159/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0307 - mse: 0.0619 - mae: 0.1793 - rmse: 0.2488\n",
      "Epoch 160/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0306 - mse: 0.0618 - mae: 0.1791 - rmse: 0.2485\n",
      "Epoch 161/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0305 - mse: 0.0615 - mae: 0.1788 - rmse: 0.2481\n",
      "Epoch 162/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0306 - mse: 0.0618 - mae: 0.1789 - rmse: 0.2486\n",
      "Epoch 163/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0306 - mse: 0.0618 - mae: 0.1789 - rmse: 0.2485\n",
      "Epoch 164/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0306 - mse: 0.0617 - mae: 0.1788 - rmse: 0.2484\n",
      "Epoch 165/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0305 - mse: 0.0616 - mae: 0.1786 - rmse: 0.2482\n",
      "Epoch 166/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0303 - mse: 0.0612 - mae: 0.1782 - rmse: 0.2473\n",
      "Epoch 167/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0305 - mse: 0.0614 - mae: 0.1785 - rmse: 0.2479\n",
      "Epoch 168/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0301 - mse: 0.0608 - mae: 0.1776 - rmse: 0.2466\n",
      "Epoch 169/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0302 - mse: 0.0609 - mae: 0.1778 - rmse: 0.2467\n",
      "Epoch 170/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0301 - mse: 0.0607 - mae: 0.1776 - rmse: 0.2464\n",
      "Epoch 171/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0303 - mse: 0.0612 - mae: 0.1783 - rmse: 0.2474\n",
      "Epoch 172/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0301 - mse: 0.0608 - mae: 0.1776 - rmse: 0.2466\n",
      "Epoch 173/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0302 - mse: 0.0609 - mae: 0.1777 - rmse: 0.2467\n",
      "Epoch 174/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0302 - mse: 0.0608 - mae: 0.1775 - rmse: 0.2466\n",
      "Epoch 175/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0300 - mse: 0.0606 - mae: 0.1773 - rmse: 0.2462\n",
      "Epoch 176/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0300 - mse: 0.0605 - mae: 0.1771 - rmse: 0.2459\n",
      "Epoch 177/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0300 - mse: 0.0605 - mae: 0.1772 - rmse: 0.2461\n",
      "Epoch 178/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0299 - mse: 0.0604 - mae: 0.1771 - rmse: 0.2458\n",
      "Epoch 179/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0299 - mse: 0.0603 - mae: 0.1767 - rmse: 0.2455\n",
      "Epoch 180/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0299 - mse: 0.0603 - mae: 0.1767 - rmse: 0.2455\n",
      "Epoch 181/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0299 - mse: 0.0602 - mae: 0.1768 - rmse: 0.2454\n",
      "Epoch 182/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0297 - mse: 0.0600 - mae: 0.1764 - rmse: 0.2449\n",
      "Epoch 183/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0299 - mse: 0.0604 - mae: 0.1767 - rmse: 0.2458\n",
      "Epoch 184/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0297 - mse: 0.0599 - mae: 0.1762 - rmse: 0.2447\n",
      "Epoch 185/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0296 - mse: 0.0597 - mae: 0.1763 - rmse: 0.2444\n",
      "Epoch 186/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0296 - mse: 0.0597 - mae: 0.1759 - rmse: 0.2444\n",
      "Epoch 187/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0295 - mse: 0.0594 - mae: 0.1756 - rmse: 0.2438\n",
      "Epoch 188/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0297 - mse: 0.0599 - mae: 0.1762 - rmse: 0.2448\n",
      "Epoch 189/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0295 - mse: 0.0596 - mae: 0.1756 - rmse: 0.2441\n",
      "Epoch 190/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0294 - mse: 0.0594 - mae: 0.1755 - rmse: 0.2437\n",
      "Epoch 191/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0295 - mse: 0.0595 - mae: 0.1757 - rmse: 0.2440\n",
      "Epoch 192/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0294 - mse: 0.0592 - mae: 0.1753 - rmse: 0.2434\n",
      "Epoch 193/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0293 - mse: 0.0591 - mae: 0.1748 - rmse: 0.2430\n",
      "Epoch 194/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0292 - mse: 0.0588 - mae: 0.1747 - rmse: 0.2425\n",
      "Epoch 195/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0292 - mse: 0.0589 - mae: 0.1746 - rmse: 0.2427\n",
      "Epoch 196/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0292 - mse: 0.0588 - mae: 0.1746 - rmse: 0.2426\n",
      "Epoch 197/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0292 - mse: 0.0589 - mae: 0.1747 - rmse: 0.2427\n",
      "Epoch 198/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0290 - mse: 0.0585 - mae: 0.1741 - rmse: 0.2419\n",
      "Epoch 199/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0292 - mse: 0.0588 - mae: 0.1745 - rmse: 0.2426\n",
      "Epoch 200/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0292 - mse: 0.0588 - mae: 0.1745 - rmse: 0.2425\n",
      "Epoch 201/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0291 - mse: 0.0588 - mae: 0.1743 - rmse: 0.2425\n",
      "Epoch 202/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0291 - mse: 0.0586 - mae: 0.1743 - rmse: 0.2422\n",
      "Epoch 203/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0290 - mse: 0.0585 - mae: 0.1742 - rmse: 0.2419\n",
      "Epoch 204/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0287 - mse: 0.0579 - mae: 0.1732 - rmse: 0.2407\n",
      "Epoch 205/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0289 - mse: 0.0583 - mae: 0.1736 - rmse: 0.2414\n",
      "Epoch 206/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0288 - mse: 0.0581 - mae: 0.1734 - rmse: 0.2409\n",
      "Epoch 207/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0287 - mse: 0.0579 - mae: 0.1732 - rmse: 0.2406\n",
      "Epoch 208/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0288 - mse: 0.0582 - mae: 0.1733 - rmse: 0.2412\n",
      "Epoch 209/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0288 - mse: 0.0580 - mae: 0.1732 - rmse: 0.2409\n",
      "Epoch 210/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0287 - mse: 0.0578 - mae: 0.1729 - rmse: 0.2405\n",
      "Epoch 211/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0287 - mse: 0.0579 - mae: 0.1729 - rmse: 0.2406\n",
      "Epoch 212/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0285 - mse: 0.0575 - mae: 0.1727 - rmse: 0.2399\n",
      "Epoch 213/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0285 - mse: 0.0575 - mae: 0.1723 - rmse: 0.2398\n",
      "Epoch 214/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0286 - mse: 0.0577 - mae: 0.1724 - rmse: 0.2401\n",
      "Epoch 215/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0286 - mse: 0.0576 - mae: 0.1725 - rmse: 0.2401\n",
      "Epoch 216/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0284 - mse: 0.0574 - mae: 0.1721 - rmse: 0.2395\n",
      "Epoch 217/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0285 - mse: 0.0574 - mae: 0.1720 - rmse: 0.2396\n",
      "Epoch 218/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0288 - mse: 0.0582 - mae: 0.1726 - rmse: 0.2413\n",
      "Epoch 219/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0286 - mse: 0.0576 - mae: 0.1721 - rmse: 0.2400\n",
      "Epoch 220/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0286 - mse: 0.0578 - mae: 0.1720 - rmse: 0.2403\n",
      "Epoch 221/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0284 - mse: 0.0572 - mae: 0.1717 - rmse: 0.2391\n",
      "Epoch 222/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0285 - mse: 0.0575 - mae: 0.1718 - rmse: 0.2398\n",
      "Epoch 223/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0284 - mse: 0.0573 - mae: 0.1717 - rmse: 0.2394\n",
      "Epoch 224/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0284 - mse: 0.0574 - mae: 0.1718 - rmse: 0.2395\n",
      "Epoch 225/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0282 - mse: 0.0568 - mae: 0.1710 - rmse: 0.2383\n",
      "Epoch 226/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0287 - mse: 0.0582 - mae: 0.1721 - rmse: 0.2411\n",
      "Epoch 227/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0284 - mse: 0.0573 - mae: 0.1713 - rmse: 0.2394\n",
      "Epoch 228/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0278 - mse: 0.0561 - mae: 0.1702 - rmse: 0.2369\n",
      "Epoch 229/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0281 - mse: 0.0567 - mae: 0.1707 - rmse: 0.2381\n",
      "Epoch 230/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0280 - mse: 0.0565 - mae: 0.1707 - rmse: 0.2376\n",
      "Epoch 231/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0280 - mse: 0.0564 - mae: 0.1703 - rmse: 0.2376\n",
      "Epoch 232/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0282 - mse: 0.0571 - mae: 0.1707 - rmse: 0.2389\n",
      "Epoch 233/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0285 - mse: 0.0577 - mae: 0.1710 - rmse: 0.2401\n",
      "Epoch 234/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0282 - mse: 0.0570 - mae: 0.1706 - rmse: 0.2388\n",
      "Epoch 235/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0280 - mse: 0.0565 - mae: 0.1701 - rmse: 0.2377\n",
      "Epoch 236/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0281 - mse: 0.0567 - mae: 0.1702 - rmse: 0.2382\n",
      "Epoch 237/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0279 - mse: 0.0563 - mae: 0.1698 - rmse: 0.2373\n",
      "Epoch 238/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0279 - mse: 0.0563 - mae: 0.1695 - rmse: 0.2372\n",
      "Epoch 239/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0277 - mse: 0.0559 - mae: 0.1692 - rmse: 0.2365\n",
      "Epoch 240/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0279 - mse: 0.0563 - mae: 0.1695 - rmse: 0.2372\n",
      "Epoch 241/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0276 - mse: 0.0555 - mae: 0.1689 - rmse: 0.2357\n",
      "Epoch 242/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0277 - mse: 0.0558 - mae: 0.1690 - rmse: 0.2362\n",
      "Epoch 243/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0278 - mse: 0.0561 - mae: 0.1692 - rmse: 0.2369\n",
      "Epoch 244/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0277 - mse: 0.0558 - mae: 0.1688 - rmse: 0.2363\n",
      "Epoch 245/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0277 - mse: 0.0558 - mae: 0.1689 - rmse: 0.2363\n",
      "Epoch 246/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0276 - mse: 0.0556 - mae: 0.1686 - rmse: 0.2358\n",
      "Epoch 247/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0275 - mse: 0.0555 - mae: 0.1684 - rmse: 0.2357\n",
      "Epoch 248/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0275 - mse: 0.0555 - mae: 0.1679 - rmse: 0.2356\n",
      "Epoch 249/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0276 - mse: 0.0557 - mae: 0.1683 - rmse: 0.2359\n",
      "Epoch 250/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0276 - mse: 0.0558 - mae: 0.1682 - rmse: 0.2361\n",
      "Epoch 251/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0273 - mse: 0.0552 - mae: 0.1675 - rmse: 0.2349\n",
      "Epoch 252/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0272 - mse: 0.0548 - mae: 0.1673 - rmse: 0.2341\n",
      "Epoch 253/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0274 - mse: 0.0553 - mae: 0.1675 - rmse: 0.2351\n",
      "Epoch 254/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0271 - mse: 0.0547 - mae: 0.1670 - rmse: 0.2338\n",
      "Epoch 255/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0272 - mse: 0.0548 - mae: 0.1672 - rmse: 0.2341\n",
      "Epoch 256/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0273 - mse: 0.0551 - mae: 0.1672 - rmse: 0.2347\n",
      "Epoch 257/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0273 - mse: 0.0552 - mae: 0.1672 - rmse: 0.2349\n",
      "Epoch 258/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0270 - mse: 0.0545 - mae: 0.1666 - rmse: 0.2334\n",
      "Epoch 259/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0273 - mse: 0.0551 - mae: 0.1669 - rmse: 0.2348\n",
      "Epoch 260/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0268 - mse: 0.0541 - mae: 0.1661 - rmse: 0.2327\n",
      "Epoch 261/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0270 - mse: 0.0545 - mae: 0.1664 - rmse: 0.2335\n",
      "Epoch 262/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0269 - mse: 0.0544 - mae: 0.1659 - rmse: 0.2332\n",
      "Epoch 263/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0272 - mse: 0.0549 - mae: 0.1664 - rmse: 0.2343\n",
      "Epoch 264/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0273 - mse: 0.0552 - mae: 0.1667 - rmse: 0.2350\n",
      "Epoch 265/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0268 - mse: 0.0541 - mae: 0.1658 - rmse: 0.2326\n",
      "Epoch 266/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0266 - mse: 0.0536 - mae: 0.1650 - rmse: 0.2314\n",
      "Epoch 267/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0268 - mse: 0.0541 - mae: 0.1656 - rmse: 0.2326\n",
      "Epoch 268/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0267 - mse: 0.0537 - mae: 0.1651 - rmse: 0.2317\n",
      "Epoch 269/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0269 - mse: 0.0542 - mae: 0.1655 - rmse: 0.2329\n",
      "Epoch 270/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0270 - mse: 0.0545 - mae: 0.1657 - rmse: 0.2335\n",
      "Epoch 271/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0269 - mse: 0.0544 - mae: 0.1654 - rmse: 0.2332\n",
      "Epoch 272/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0266 - mse: 0.0538 - mae: 0.1648 - rmse: 0.2319\n",
      "Epoch 273/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0265 - mse: 0.0534 - mae: 0.1647 - rmse: 0.2311\n",
      "Epoch 274/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0264 - mse: 0.0533 - mae: 0.1643 - rmse: 0.2308\n",
      "Epoch 275/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0265 - mse: 0.0533 - mae: 0.1643 - rmse: 0.2310\n",
      "Epoch 276/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0266 - mse: 0.0537 - mae: 0.1645 - rmse: 0.2317\n",
      "Epoch 277/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0265 - mse: 0.0534 - mae: 0.1641 - rmse: 0.2310\n",
      "Epoch 278/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0265 - mse: 0.0535 - mae: 0.1644 - rmse: 0.2312\n",
      "Epoch 279/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0262 - mse: 0.0528 - mae: 0.1637 - rmse: 0.2299\n",
      "Epoch 280/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0265 - mse: 0.0534 - mae: 0.1642 - rmse: 0.2312\n",
      "Epoch 281/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0262 - mse: 0.0527 - mae: 0.1632 - rmse: 0.2297\n",
      "Epoch 282/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0265 - mse: 0.0536 - mae: 0.1640 - rmse: 0.2314\n",
      "Epoch 283/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0265 - mse: 0.0535 - mae: 0.1641 - rmse: 0.2314\n",
      "Epoch 284/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0263 - mse: 0.0529 - mae: 0.1635 - rmse: 0.2301\n",
      "Epoch 285/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0261 - mse: 0.0526 - mae: 0.1631 - rmse: 0.2294\n",
      "Epoch 286/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0263 - mse: 0.0531 - mae: 0.1632 - rmse: 0.2304\n",
      "Epoch 287/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0263 - mse: 0.0532 - mae: 0.1634 - rmse: 0.2307\n",
      "Epoch 288/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0262 - mse: 0.0528 - mae: 0.1631 - rmse: 0.2298\n",
      "Epoch 289/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0262 - mse: 0.0527 - mae: 0.1628 - rmse: 0.2296\n",
      "Epoch 290/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0260 - mse: 0.0525 - mae: 0.1625 - rmse: 0.2291\n",
      "Epoch 291/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0260 - mse: 0.0524 - mae: 0.1626 - rmse: 0.2290\n",
      "Epoch 292/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0264 - mse: 0.0532 - mae: 0.1630 - rmse: 0.2307\n",
      "Epoch 293/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0259 - mse: 0.0522 - mae: 0.1622 - rmse: 0.2285\n",
      "Epoch 294/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0261 - mse: 0.0526 - mae: 0.1625 - rmse: 0.2293\n",
      "Epoch 295/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0260 - mse: 0.0524 - mae: 0.1623 - rmse: 0.2289\n",
      "Epoch 296/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0258 - mse: 0.0521 - mae: 0.1618 - rmse: 0.2282\n",
      "Epoch 297/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0260 - mse: 0.0525 - mae: 0.1623 - rmse: 0.2291\n",
      "Epoch 298/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0256 - mse: 0.0515 - mae: 0.1612 - rmse: 0.2270\n",
      "Epoch 299/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0258 - mse: 0.0519 - mae: 0.1616 - rmse: 0.2278\n",
      "Epoch 300/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0259 - mse: 0.0522 - mae: 0.1620 - rmse: 0.2285\n",
      "Epoch 301/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0258 - mse: 0.0520 - mae: 0.1615 - rmse: 0.2280\n",
      "Epoch 302/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0259 - mse: 0.0522 - mae: 0.1618 - rmse: 0.2284\n",
      "Epoch 303/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0256 - mse: 0.0516 - mae: 0.1611 - rmse: 0.2272\n",
      "Epoch 304/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0258 - mse: 0.0520 - mae: 0.1614 - rmse: 0.2281\n",
      "Epoch 305/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0257 - mse: 0.0517 - mae: 0.1613 - rmse: 0.2274\n",
      "Epoch 306/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0256 - mse: 0.0516 - mae: 0.1610 - rmse: 0.2271\n",
      "Epoch 307/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0257 - mse: 0.0519 - mae: 0.1613 - rmse: 0.2277\n",
      "Epoch 308/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0257 - mse: 0.0519 - mae: 0.1610 - rmse: 0.2277\n",
      "Epoch 309/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0255 - mse: 0.0515 - mae: 0.1607 - rmse: 0.2269\n",
      "Epoch 310/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0256 - mse: 0.0517 - mae: 0.1610 - rmse: 0.2273\n",
      "Epoch 311/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0258 - mse: 0.0520 - mae: 0.1610 - rmse: 0.2281\n",
      "Epoch 312/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0255 - mse: 0.0514 - mae: 0.1605 - rmse: 0.2268\n",
      "Epoch 313/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0254 - mse: 0.0511 - mae: 0.1602 - rmse: 0.2261\n",
      "Epoch 314/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0255 - mse: 0.0515 - mae: 0.1605 - rmse: 0.2269\n",
      "Epoch 315/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0258 - mse: 0.0522 - mae: 0.1609 - rmse: 0.2285\n",
      "Epoch 316/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0254 - mse: 0.0511 - mae: 0.1603 - rmse: 0.2262\n",
      "Epoch 317/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0254 - mse: 0.0512 - mae: 0.1602 - rmse: 0.2264\n",
      "Epoch 318/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0255 - mse: 0.0515 - mae: 0.1602 - rmse: 0.2269\n",
      "Epoch 319/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0254 - mse: 0.0512 - mae: 0.1599 - rmse: 0.2263\n",
      "Epoch 320/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0254 - mse: 0.0513 - mae: 0.1600 - rmse: 0.2266\n",
      "Epoch 321/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0257 - mse: 0.0518 - mae: 0.1604 - rmse: 0.2277\n",
      "Epoch 322/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0252 - mse: 0.0507 - mae: 0.1593 - rmse: 0.2253\n",
      "Epoch 323/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0254 - mse: 0.0512 - mae: 0.1598 - rmse: 0.2263\n",
      "Epoch 324/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0253 - mse: 0.0511 - mae: 0.1597 - rmse: 0.2260\n",
      "Epoch 325/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0252 - mse: 0.0508 - mae: 0.1596 - rmse: 0.2254\n",
      "Epoch 326/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0252 - mse: 0.0507 - mae: 0.1593 - rmse: 0.2252\n",
      "Epoch 327/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0252 - mse: 0.0509 - mae: 0.1591 - rmse: 0.2255\n",
      "Epoch 328/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0251 - mse: 0.0507 - mae: 0.1591 - rmse: 0.2251\n",
      "Epoch 329/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0251 - mse: 0.0506 - mae: 0.1589 - rmse: 0.2249\n",
      "Epoch 330/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0250 - mse: 0.0504 - mae: 0.1588 - rmse: 0.2245\n",
      "Epoch 331/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0251 - mse: 0.0506 - mae: 0.1589 - rmse: 0.2249\n",
      "Epoch 332/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0250 - mse: 0.0504 - mae: 0.1587 - rmse: 0.2246\n",
      "Epoch 333/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0251 - mse: 0.0505 - mae: 0.1587 - rmse: 0.2248\n",
      "Epoch 334/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0250 - mse: 0.0504 - mae: 0.1584 - rmse: 0.2246\n",
      "Epoch 335/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0251 - mse: 0.0506 - mae: 0.1589 - rmse: 0.2248\n",
      "Epoch 336/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0252 - mse: 0.0507 - mae: 0.1589 - rmse: 0.2252\n",
      "Epoch 337/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0250 - mse: 0.0503 - mae: 0.1584 - rmse: 0.2243\n",
      "Epoch 338/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0251 - mse: 0.0507 - mae: 0.1589 - rmse: 0.2252\n",
      "Epoch 339/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0249 - mse: 0.0502 - mae: 0.1584 - rmse: 0.2242\n",
      "Epoch 340/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0249 - mse: 0.0502 - mae: 0.1581 - rmse: 0.2239\n",
      "Epoch 341/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0250 - mse: 0.0504 - mae: 0.1584 - rmse: 0.2245\n",
      "Epoch 342/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0249 - mse: 0.0502 - mae: 0.1579 - rmse: 0.2241\n",
      "Epoch 343/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0249 - mse: 0.0502 - mae: 0.1582 - rmse: 0.2241\n",
      "Epoch 344/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0250 - mse: 0.0503 - mae: 0.1582 - rmse: 0.2243\n",
      "Epoch 345/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0250 - mse: 0.0504 - mae: 0.1583 - rmse: 0.2245\n",
      "Epoch 346/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0249 - mse: 0.0501 - mae: 0.1579 - rmse: 0.2238\n",
      "Epoch 347/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0247 - mse: 0.0498 - mae: 0.1577 - rmse: 0.2232\n",
      "Epoch 348/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0250 - mse: 0.0505 - mae: 0.1582 - rmse: 0.2247\n",
      "Epoch 349/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0249 - mse: 0.0503 - mae: 0.1579 - rmse: 0.2243\n",
      "Epoch 350/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0247 - mse: 0.0499 - mae: 0.1574 - rmse: 0.2233\n",
      "Epoch 351/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0247 - mse: 0.0498 - mae: 0.1574 - rmse: 0.2231\n",
      "Epoch 352/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0248 - mse: 0.0500 - mae: 0.1577 - rmse: 0.2235\n",
      "Epoch 353/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0247 - mse: 0.0498 - mae: 0.1573 - rmse: 0.2232\n",
      "Epoch 354/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0247 - mse: 0.0499 - mae: 0.1573 - rmse: 0.2233\n",
      "Epoch 355/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0247 - mse: 0.0498 - mae: 0.1573 - rmse: 0.2231\n",
      "Epoch 356/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0247 - mse: 0.0497 - mae: 0.1573 - rmse: 0.2230\n",
      "Epoch 357/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0247 - mse: 0.0499 - mae: 0.1574 - rmse: 0.2233\n",
      "Epoch 358/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0246 - mse: 0.0496 - mae: 0.1573 - rmse: 0.2227\n",
      "Epoch 359/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0250 - mse: 0.0505 - mae: 0.1578 - rmse: 0.2247\n",
      "Epoch 360/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0247 - mse: 0.0498 - mae: 0.1572 - rmse: 0.2232\n",
      "Epoch 361/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0247 - mse: 0.0497 - mae: 0.1572 - rmse: 0.2230\n",
      "Epoch 362/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0245 - mse: 0.0494 - mae: 0.1570 - rmse: 0.2224\n",
      "Epoch 363/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0247 - mse: 0.0498 - mae: 0.1570 - rmse: 0.2232\n",
      "Epoch 364/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0244 - mse: 0.0492 - mae: 0.1566 - rmse: 0.2219\n",
      "Epoch 365/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0247 - mse: 0.0499 - mae: 0.1572 - rmse: 0.2234\n",
      "Epoch 366/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0244 - mse: 0.0492 - mae: 0.1563 - rmse: 0.2219\n",
      "Epoch 367/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0245 - mse: 0.0494 - mae: 0.1567 - rmse: 0.2223\n",
      "Epoch 368/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0244 - mse: 0.0492 - mae: 0.1566 - rmse: 0.2218\n",
      "Epoch 369/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0245 - mse: 0.0494 - mae: 0.1565 - rmse: 0.2222\n",
      "Epoch 370/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0244 - mse: 0.0491 - mae: 0.1562 - rmse: 0.2216\n",
      "Epoch 371/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0247 - mse: 0.0499 - mae: 0.1569 - rmse: 0.2234\n",
      "Epoch 372/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0248 - mse: 0.0499 - mae: 0.1569 - rmse: 0.2235\n",
      "Epoch 373/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0244 - mse: 0.0491 - mae: 0.1564 - rmse: 0.2216\n",
      "Epoch 374/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0245 - mse: 0.0494 - mae: 0.1564 - rmse: 0.2222\n",
      "Epoch 375/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0244 - mse: 0.0492 - mae: 0.1563 - rmse: 0.2217\n",
      "Epoch 376/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0244 - mse: 0.0493 - mae: 0.1561 - rmse: 0.2220\n",
      "Epoch 377/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0244 - mse: 0.0493 - mae: 0.1561 - rmse: 0.2220\n",
      "Epoch 378/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0246 - mse: 0.0496 - mae: 0.1567 - rmse: 0.2227\n",
      "Epoch 379/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0243 - mse: 0.0489 - mae: 0.1560 - rmse: 0.2212\n",
      "Epoch 380/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0244 - mse: 0.0493 - mae: 0.1561 - rmse: 0.2220\n",
      "Epoch 381/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0244 - mse: 0.0491 - mae: 0.1560 - rmse: 0.2216\n",
      "Epoch 382/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0242 - mse: 0.0488 - mae: 0.1557 - rmse: 0.2209\n",
      "Epoch 383/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0242 - mse: 0.0489 - mae: 0.1556 - rmse: 0.2211\n",
      "Epoch 384/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0244 - mse: 0.0492 - mae: 0.1560 - rmse: 0.2217\n",
      "Epoch 385/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0244 - mse: 0.0493 - mae: 0.1560 - rmse: 0.2221\n",
      "Epoch 386/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0243 - mse: 0.0490 - mae: 0.1558 - rmse: 0.2213\n",
      "Epoch 387/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0240 - mse: 0.0484 - mae: 0.1552 - rmse: 0.2200\n",
      "Epoch 388/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0241 - mse: 0.0485 - mae: 0.1553 - rmse: 0.2202\n",
      "Epoch 389/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0243 - mse: 0.0491 - mae: 0.1558 - rmse: 0.2216\n",
      "Epoch 390/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0245 - mse: 0.0494 - mae: 0.1560 - rmse: 0.2222\n",
      "Epoch 391/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0241 - mse: 0.0485 - mae: 0.1553 - rmse: 0.2203\n",
      "Epoch 392/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0246 - mse: 0.0496 - mae: 0.1560 - rmse: 0.2226\n",
      "Epoch 393/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0243 - mse: 0.0490 - mae: 0.1556 - rmse: 0.2214\n",
      "Epoch 394/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0240 - mse: 0.0484 - mae: 0.1551 - rmse: 0.2199\n",
      "Epoch 395/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0240 - mse: 0.0485 - mae: 0.1550 - rmse: 0.2201\n",
      "Epoch 396/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0241 - mse: 0.0486 - mae: 0.1552 - rmse: 0.2205\n",
      "Epoch 397/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0242 - mse: 0.0489 - mae: 0.1554 - rmse: 0.2212\n",
      "Epoch 398/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0240 - mse: 0.0484 - mae: 0.1551 - rmse: 0.2201\n",
      "Epoch 399/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0241 - mse: 0.0485 - mae: 0.1549 - rmse: 0.2203\n",
      "Epoch 400/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0241 - mse: 0.0485 - mae: 0.1551 - rmse: 0.2203\n",
      "Epoch 401/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0240 - mse: 0.0483 - mae: 0.1548 - rmse: 0.2197\n",
      "Epoch 402/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0240 - mse: 0.0484 - mae: 0.1548 - rmse: 0.2201\n",
      "Epoch 403/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0239 - mse: 0.0482 - mae: 0.1548 - rmse: 0.2196\n",
      "Epoch 404/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0242 - mse: 0.0487 - mae: 0.1552 - rmse: 0.2207\n",
      "Epoch 405/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0239 - mse: 0.0482 - mae: 0.1547 - rmse: 0.2196\n",
      "Epoch 406/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0239 - mse: 0.0482 - mae: 0.1543 - rmse: 0.2195\n",
      "Epoch 407/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0240 - mse: 0.0484 - mae: 0.1549 - rmse: 0.2199\n",
      "Epoch 408/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0241 - mse: 0.0485 - mae: 0.1549 - rmse: 0.2202\n",
      "Epoch 409/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0242 - mse: 0.0488 - mae: 0.1552 - rmse: 0.2208\n",
      "Epoch 410/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0239 - mse: 0.0482 - mae: 0.1546 - rmse: 0.2195\n",
      "Epoch 411/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0240 - mse: 0.0485 - mae: 0.1547 - rmse: 0.2202\n",
      "Epoch 412/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0243 - mse: 0.0490 - mae: 0.1552 - rmse: 0.2213\n",
      "Epoch 413/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0238 - mse: 0.0480 - mae: 0.1543 - rmse: 0.2191\n",
      "Epoch 414/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0239 - mse: 0.0482 - mae: 0.1545 - rmse: 0.2195\n",
      "Epoch 415/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0239 - mse: 0.0482 - mae: 0.1546 - rmse: 0.2196\n",
      "Epoch 416/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0238 - mse: 0.0480 - mae: 0.1543 - rmse: 0.2190\n",
      "Epoch 417/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0239 - mse: 0.0481 - mae: 0.1543 - rmse: 0.2194\n",
      "Epoch 418/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0239 - mse: 0.0482 - mae: 0.1542 - rmse: 0.2195\n",
      "Epoch 419/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0239 - mse: 0.0482 - mae: 0.1546 - rmse: 0.2196\n",
      "Epoch 420/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0239 - mse: 0.0481 - mae: 0.1543 - rmse: 0.2192\n",
      "Epoch 421/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0239 - mse: 0.0482 - mae: 0.1543 - rmse: 0.2196\n",
      "Epoch 422/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0238 - mse: 0.0480 - mae: 0.1542 - rmse: 0.2191\n",
      "Epoch 423/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0237 - mse: 0.0478 - mae: 0.1540 - rmse: 0.2186\n",
      "Epoch 424/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0240 - mse: 0.0483 - mae: 0.1544 - rmse: 0.2198\n",
      "Epoch 425/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0241 - mse: 0.0486 - mae: 0.1549 - rmse: 0.2205\n",
      "Epoch 426/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0238 - mse: 0.0480 - mae: 0.1541 - rmse: 0.2192\n",
      "Epoch 427/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0238 - mse: 0.0481 - mae: 0.1541 - rmse: 0.2193\n",
      "Epoch 428/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0239 - mse: 0.0482 - mae: 0.1541 - rmse: 0.2196\n",
      "Epoch 429/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0237 - mse: 0.0478 - mae: 0.1537 - rmse: 0.2187\n",
      "Epoch 430/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0237 - mse: 0.0478 - mae: 0.1538 - rmse: 0.2185\n",
      "Epoch 431/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0237 - mse: 0.0477 - mae: 0.1538 - rmse: 0.2184\n",
      "Epoch 432/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0238 - mse: 0.0480 - mae: 0.1538 - rmse: 0.2191\n",
      "Epoch 433/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0238 - mse: 0.0479 - mae: 0.1538 - rmse: 0.2189\n",
      "Epoch 434/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0238 - mse: 0.0480 - mae: 0.1540 - rmse: 0.2192\n",
      "Epoch 435/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0237 - mse: 0.0477 - mae: 0.1536 - rmse: 0.2185\n",
      "Epoch 436/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0239 - mse: 0.0481 - mae: 0.1540 - rmse: 0.2193\n",
      "Epoch 437/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0238 - mse: 0.0480 - mae: 0.1538 - rmse: 0.2190\n",
      "Epoch 438/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0236 - mse: 0.0476 - mae: 0.1535 - rmse: 0.2181\n",
      "Epoch 439/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0237 - mse: 0.0478 - mae: 0.1535 - rmse: 0.2186\n",
      "Epoch 440/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0237 - mse: 0.0478 - mae: 0.1536 - rmse: 0.2186\n",
      "Epoch 441/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0236 - mse: 0.0476 - mae: 0.1534 - rmse: 0.2181\n",
      "Epoch 442/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0238 - mse: 0.0480 - mae: 0.1538 - rmse: 0.2191\n",
      "Epoch 443/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0236 - mse: 0.0476 - mae: 0.1533 - rmse: 0.2182\n",
      "Epoch 444/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0236 - mse: 0.0477 - mae: 0.1534 - rmse: 0.2183\n",
      "Epoch 445/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0236 - mse: 0.0475 - mae: 0.1533 - rmse: 0.2180\n",
      "Epoch 446/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0240 - mse: 0.0485 - mae: 0.1542 - rmse: 0.2203\n",
      "Epoch 447/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0237 - mse: 0.0479 - mae: 0.1536 - rmse: 0.2189\n",
      "Epoch 448/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0235 - mse: 0.0474 - mae: 0.1530 - rmse: 0.2178\n",
      "Epoch 449/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0237 - mse: 0.0477 - mae: 0.1535 - rmse: 0.2184\n",
      "Epoch 450/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0237 - mse: 0.0478 - mae: 0.1535 - rmse: 0.2186\n",
      "Epoch 451/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0236 - mse: 0.0475 - mae: 0.1534 - rmse: 0.2181\n",
      "Epoch 452/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0237 - mse: 0.0478 - mae: 0.1535 - rmse: 0.2187\n",
      "Epoch 453/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0238 - mse: 0.0479 - mae: 0.1537 - rmse: 0.2190\n",
      "Epoch 454/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0235 - mse: 0.0474 - mae: 0.1530 - rmse: 0.2178\n",
      "Epoch 455/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0236 - mse: 0.0476 - mae: 0.1531 - rmse: 0.2182\n",
      "Epoch 456/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0234 - mse: 0.0470 - mae: 0.1526 - rmse: 0.2169\n",
      "Epoch 457/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0235 - mse: 0.0474 - mae: 0.1530 - rmse: 0.2177\n",
      "Epoch 458/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0237 - mse: 0.0479 - mae: 0.1534 - rmse: 0.2189\n",
      "Epoch 459/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0236 - mse: 0.0476 - mae: 0.1531 - rmse: 0.2181\n",
      "Epoch 460/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0236 - mse: 0.0476 - mae: 0.1532 - rmse: 0.2182\n",
      "Epoch 461/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0237 - mse: 0.0478 - mae: 0.1532 - rmse: 0.2186\n",
      "Epoch 462/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0238 - mse: 0.0480 - mae: 0.1535 - rmse: 0.2191\n",
      "Epoch 463/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0237 - mse: 0.0477 - mae: 0.1532 - rmse: 0.2185\n",
      "Epoch 464/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0237 - mse: 0.0479 - mae: 0.1533 - rmse: 0.2188\n",
      "Epoch 465/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0235 - mse: 0.0473 - mae: 0.1527 - rmse: 0.2175\n",
      "Epoch 466/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0234 - mse: 0.0472 - mae: 0.1528 - rmse: 0.2172\n",
      "Epoch 467/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0232 - mse: 0.0468 - mae: 0.1522 - rmse: 0.2163\n",
      "Epoch 468/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0234 - mse: 0.0470 - mae: 0.1524 - rmse: 0.2169\n",
      "Epoch 469/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0235 - mse: 0.0473 - mae: 0.1528 - rmse: 0.2174\n",
      "Epoch 470/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0236 - mse: 0.0475 - mae: 0.1529 - rmse: 0.2180\n",
      "Epoch 471/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0234 - mse: 0.0471 - mae: 0.1527 - rmse: 0.2171\n",
      "Epoch 472/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0235 - mse: 0.0473 - mae: 0.1527 - rmse: 0.2175\n",
      "Epoch 473/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0234 - mse: 0.0471 - mae: 0.1525 - rmse: 0.2171\n",
      "Epoch 474/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0233 - mse: 0.0469 - mae: 0.1523 - rmse: 0.2165\n",
      "Epoch 475/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0234 - mse: 0.0472 - mae: 0.1526 - rmse: 0.2172\n",
      "Epoch 476/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0234 - mse: 0.0472 - mae: 0.1523 - rmse: 0.2171\n",
      "Epoch 477/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0234 - mse: 0.0472 - mae: 0.1524 - rmse: 0.2171\n",
      "Epoch 478/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0234 - mse: 0.0472 - mae: 0.1523 - rmse: 0.2173\n",
      "Epoch 479/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0233 - mse: 0.0469 - mae: 0.1521 - rmse: 0.2166\n",
      "Epoch 480/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0233 - mse: 0.0469 - mae: 0.1520 - rmse: 0.2165\n",
      "Epoch 481/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0232 - mse: 0.0467 - mae: 0.1519 - rmse: 0.2162\n",
      "Epoch 482/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0232 - mse: 0.0467 - mae: 0.1518 - rmse: 0.2162\n",
      "Epoch 483/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0233 - mse: 0.0469 - mae: 0.1520 - rmse: 0.2165\n",
      "Epoch 484/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0233 - mse: 0.0469 - mae: 0.1520 - rmse: 0.2166\n",
      "Epoch 485/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0232 - mse: 0.0468 - mae: 0.1520 - rmse: 0.2163\n",
      "Epoch 486/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0232 - mse: 0.0468 - mae: 0.1518 - rmse: 0.2163\n",
      "Epoch 487/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0233 - mse: 0.0469 - mae: 0.1521 - rmse: 0.2166\n",
      "Epoch 488/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0232 - mse: 0.0467 - mae: 0.1517 - rmse: 0.2161\n",
      "Epoch 489/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0232 - mse: 0.0467 - mae: 0.1518 - rmse: 0.2161\n",
      "Epoch 490/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0232 - mse: 0.0467 - mae: 0.1519 - rmse: 0.2162\n",
      "Epoch 491/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0232 - mse: 0.0468 - mae: 0.1520 - rmse: 0.2164\n",
      "Epoch 492/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0231 - mse: 0.0466 - mae: 0.1516 - rmse: 0.2159\n",
      "Epoch 493/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0232 - mse: 0.0467 - mae: 0.1515 - rmse: 0.2161\n",
      "Epoch 494/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0232 - mse: 0.0466 - mae: 0.1519 - rmse: 0.2160\n",
      "Epoch 495/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0230 - mse: 0.0464 - mae: 0.1513 - rmse: 0.2153\n",
      "Epoch 496/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0233 - mse: 0.0469 - mae: 0.1518 - rmse: 0.2166\n",
      "Epoch 497/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0231 - mse: 0.0466 - mae: 0.1517 - rmse: 0.2160\n",
      "Epoch 498/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0232 - mse: 0.0468 - mae: 0.1519 - rmse: 0.2162\n",
      "Epoch 499/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0231 - mse: 0.0466 - mae: 0.1517 - rmse: 0.2158\n",
      "Epoch 500/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0231 - mse: 0.0466 - mae: 0.1516 - rmse: 0.2159\n",
      "Epoch 501/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0230 - mse: 0.0465 - mae: 0.1513 - rmse: 0.2155\n",
      "Epoch 502/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0231 - mse: 0.0466 - mae: 0.1514 - rmse: 0.2159\n",
      "Epoch 503/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0232 - mse: 0.0468 - mae: 0.1519 - rmse: 0.2163\n",
      "Epoch 504/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0231 - mse: 0.0466 - mae: 0.1515 - rmse: 0.2158\n",
      "Epoch 505/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0232 - mse: 0.0468 - mae: 0.1517 - rmse: 0.2164\n",
      "Epoch 506/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0231 - mse: 0.0466 - mae: 0.1516 - rmse: 0.2160\n",
      "Epoch 507/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0233 - mse: 0.0469 - mae: 0.1518 - rmse: 0.2166\n",
      "Epoch 508/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0229 - mse: 0.0462 - mae: 0.1510 - rmse: 0.2150\n",
      "Epoch 509/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0231 - mse: 0.0466 - mae: 0.1514 - rmse: 0.2160\n",
      "Epoch 510/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0230 - mse: 0.0463 - mae: 0.1511 - rmse: 0.2151\n",
      "Epoch 511/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0231 - mse: 0.0465 - mae: 0.1514 - rmse: 0.2155\n",
      "Epoch 512/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0231 - mse: 0.0465 - mae: 0.1513 - rmse: 0.2156\n",
      "Epoch 513/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0231 - mse: 0.0465 - mae: 0.1513 - rmse: 0.2157\n",
      "Epoch 514/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0231 - mse: 0.0464 - mae: 0.1513 - rmse: 0.2155\n",
      "Epoch 515/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0231 - mse: 0.0466 - mae: 0.1514 - rmse: 0.2159\n",
      "Epoch 516/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0230 - mse: 0.0464 - mae: 0.1513 - rmse: 0.2154\n",
      "Epoch 517/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0230 - mse: 0.0463 - mae: 0.1510 - rmse: 0.2152\n",
      "Epoch 518/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0230 - mse: 0.0464 - mae: 0.1511 - rmse: 0.2154\n",
      "Epoch 519/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0230 - mse: 0.0464 - mae: 0.1510 - rmse: 0.2155\n",
      "Epoch 520/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0229 - mse: 0.0462 - mae: 0.1508 - rmse: 0.2150\n",
      "Epoch 521/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0230 - mse: 0.0464 - mae: 0.1511 - rmse: 0.2154\n",
      "Epoch 522/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0230 - mse: 0.0463 - mae: 0.1511 - rmse: 0.2152\n",
      "Epoch 523/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0228 - mse: 0.0460 - mae: 0.1508 - rmse: 0.2145\n",
      "Epoch 524/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0232 - mse: 0.0468 - mae: 0.1514 - rmse: 0.2162\n",
      "Epoch 525/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0230 - mse: 0.0464 - mae: 0.1509 - rmse: 0.2154\n",
      "Epoch 526/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0228 - mse: 0.0460 - mae: 0.1505 - rmse: 0.2145\n",
      "Epoch 527/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0229 - mse: 0.0461 - mae: 0.1507 - rmse: 0.2146\n",
      "Epoch 528/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0229 - mse: 0.0462 - mae: 0.1508 - rmse: 0.2150\n",
      "Epoch 529/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0231 - mse: 0.0467 - mae: 0.1513 - rmse: 0.2160\n",
      "Epoch 530/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0230 - mse: 0.0464 - mae: 0.1510 - rmse: 0.2154\n",
      "Epoch 531/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0230 - mse: 0.0464 - mae: 0.1510 - rmse: 0.2154\n",
      "Epoch 532/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0230 - mse: 0.0463 - mae: 0.1510 - rmse: 0.2152\n",
      "Epoch 533/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0229 - mse: 0.0461 - mae: 0.1508 - rmse: 0.2148\n",
      "Epoch 534/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0229 - mse: 0.0462 - mae: 0.1508 - rmse: 0.2149\n",
      "Epoch 535/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0229 - mse: 0.0461 - mae: 0.1506 - rmse: 0.2146\n",
      "Epoch 536/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0230 - mse: 0.0463 - mae: 0.1506 - rmse: 0.2151\n",
      "Epoch 537/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0230 - mse: 0.0463 - mae: 0.1510 - rmse: 0.2151\n",
      "Epoch 538/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0229 - mse: 0.0462 - mae: 0.1508 - rmse: 0.2150\n",
      "Epoch 539/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0229 - mse: 0.0462 - mae: 0.1505 - rmse: 0.2150\n",
      "Epoch 540/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0229 - mse: 0.0462 - mae: 0.1507 - rmse: 0.2149\n",
      "Epoch 541/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0230 - mse: 0.0463 - mae: 0.1508 - rmse: 0.2153\n",
      "Epoch 542/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0231 - mse: 0.0466 - mae: 0.1510 - rmse: 0.2159\n",
      "Epoch 543/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0231 - mse: 0.0466 - mae: 0.1510 - rmse: 0.2158\n",
      "Epoch 544/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0228 - mse: 0.0459 - mae: 0.1503 - rmse: 0.2142\n",
      "Epoch 545/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0227 - mse: 0.0458 - mae: 0.1500 - rmse: 0.2139\n",
      "Epoch 546/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0229 - mse: 0.0462 - mae: 0.1505 - rmse: 0.2148\n",
      "Epoch 547/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0229 - mse: 0.0460 - mae: 0.1504 - rmse: 0.2146\n",
      "Epoch 548/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0228 - mse: 0.0460 - mae: 0.1502 - rmse: 0.2146\n",
      "Epoch 549/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0228 - mse: 0.0459 - mae: 0.1501 - rmse: 0.2142\n",
      "Epoch 550/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0230 - mse: 0.0466 - mae: 0.1509 - rmse: 0.2158\n",
      "Epoch 551/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0228 - mse: 0.0459 - mae: 0.1503 - rmse: 0.2142\n",
      "Epoch 552/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0228 - mse: 0.0459 - mae: 0.1503 - rmse: 0.2143\n",
      "Epoch 553/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0230 - mse: 0.0464 - mae: 0.1506 - rmse: 0.2154\n",
      "Epoch 554/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0230 - mse: 0.0464 - mae: 0.1506 - rmse: 0.2155\n",
      "Epoch 555/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0232 - mse: 0.0467 - mae: 0.1510 - rmse: 0.2162\n",
      "Epoch 556/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0227 - mse: 0.0458 - mae: 0.1500 - rmse: 0.2141\n",
      "Epoch 557/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0229 - mse: 0.0462 - mae: 0.1505 - rmse: 0.2150\n",
      "Epoch 558/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0227 - mse: 0.0458 - mae: 0.1499 - rmse: 0.2139\n",
      "Epoch 559/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0227 - mse: 0.0458 - mae: 0.1501 - rmse: 0.2140\n",
      "Epoch 560/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0228 - mse: 0.0460 - mae: 0.1503 - rmse: 0.2145\n",
      "Epoch 561/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0229 - mse: 0.0462 - mae: 0.1504 - rmse: 0.2148\n",
      "Epoch 562/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0230 - mse: 0.0463 - mae: 0.1506 - rmse: 0.2151\n",
      "Epoch 563/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0227 - mse: 0.0458 - mae: 0.1499 - rmse: 0.2139\n",
      "Epoch 564/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0226 - mse: 0.0456 - mae: 0.1497 - rmse: 0.2135\n",
      "Epoch 565/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0229 - mse: 0.0461 - mae: 0.1501 - rmse: 0.2148\n",
      "Epoch 566/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0229 - mse: 0.0462 - mae: 0.1504 - rmse: 0.2150\n",
      "Epoch 567/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0229 - mse: 0.0462 - mae: 0.1504 - rmse: 0.2150\n",
      "Epoch 568/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0226 - mse: 0.0456 - mae: 0.1495 - rmse: 0.2135\n",
      "Epoch 569/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0228 - mse: 0.0460 - mae: 0.1499 - rmse: 0.2145\n",
      "Epoch 570/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0228 - mse: 0.0459 - mae: 0.1498 - rmse: 0.2141\n",
      "Epoch 571/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0227 - mse: 0.0458 - mae: 0.1501 - rmse: 0.2140\n",
      "Epoch 572/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0226 - mse: 0.0457 - mae: 0.1495 - rmse: 0.2137\n",
      "Epoch 573/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0228 - mse: 0.0458 - mae: 0.1500 - rmse: 0.2141\n",
      "Epoch 574/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0228 - mse: 0.0459 - mae: 0.1500 - rmse: 0.2142\n",
      "Epoch 575/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0226 - mse: 0.0456 - mae: 0.1495 - rmse: 0.2134\n",
      "Epoch 576/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0228 - mse: 0.0459 - mae: 0.1500 - rmse: 0.2142\n",
      "Epoch 577/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0226 - mse: 0.0456 - mae: 0.1494 - rmse: 0.2135\n",
      "Epoch 578/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0226 - mse: 0.0456 - mae: 0.1495 - rmse: 0.2135\n",
      "Epoch 579/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0229 - mse: 0.0462 - mae: 0.1502 - rmse: 0.2150\n",
      "Epoch 580/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0229 - mse: 0.0461 - mae: 0.1500 - rmse: 0.2147\n",
      "Epoch 581/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0228 - mse: 0.0459 - mae: 0.1498 - rmse: 0.2142\n",
      "Epoch 582/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0227 - mse: 0.0457 - mae: 0.1498 - rmse: 0.2137\n",
      "Epoch 583/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0227 - mse: 0.0457 - mae: 0.1498 - rmse: 0.2138\n",
      "Epoch 584/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0226 - mse: 0.0456 - mae: 0.1496 - rmse: 0.2136\n",
      "Epoch 585/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0230 - mse: 0.0466 - mae: 0.1502 - rmse: 0.2159\n",
      "Epoch 586/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0227 - mse: 0.0458 - mae: 0.1496 - rmse: 0.2139\n",
      "Epoch 587/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0228 - mse: 0.0459 - mae: 0.1499 - rmse: 0.2143\n",
      "Epoch 588/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0227 - mse: 0.0456 - mae: 0.1497 - rmse: 0.2136\n",
      "Epoch 589/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0228 - mse: 0.0459 - mae: 0.1498 - rmse: 0.2143\n",
      "Epoch 590/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0226 - mse: 0.0455 - mae: 0.1492 - rmse: 0.2133\n",
      "Epoch 591/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0228 - mse: 0.0462 - mae: 0.1498 - rmse: 0.2149\n",
      "Epoch 592/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0225 - mse: 0.0454 - mae: 0.1493 - rmse: 0.2130\n",
      "Epoch 593/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0227 - mse: 0.0457 - mae: 0.1495 - rmse: 0.2138\n",
      "Epoch 594/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0226 - mse: 0.0455 - mae: 0.1493 - rmse: 0.2132\n",
      "Epoch 595/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0226 - mse: 0.0457 - mae: 0.1494 - rmse: 0.2138\n",
      "Epoch 596/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0226 - mse: 0.0455 - mae: 0.1494 - rmse: 0.2134\n",
      "Epoch 597/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0228 - mse: 0.0460 - mae: 0.1498 - rmse: 0.2144\n",
      "Epoch 598/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0226 - mse: 0.0456 - mae: 0.1495 - rmse: 0.2136\n",
      "Epoch 599/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0226 - mse: 0.0456 - mae: 0.1492 - rmse: 0.2136\n",
      "Epoch 600/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0225 - mse: 0.0454 - mae: 0.1492 - rmse: 0.2131\n",
      "Epoch 601/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0225 - mse: 0.0453 - mae: 0.1489 - rmse: 0.2128\n",
      "Epoch 602/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0227 - mse: 0.0458 - mae: 0.1497 - rmse: 0.2141\n",
      "Epoch 603/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0227 - mse: 0.0458 - mae: 0.1495 - rmse: 0.2140\n",
      "Epoch 604/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0226 - mse: 0.0457 - mae: 0.1494 - rmse: 0.2137\n",
      "Epoch 605/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0226 - mse: 0.0455 - mae: 0.1493 - rmse: 0.2133\n",
      "Epoch 606/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0224 - mse: 0.0451 - mae: 0.1486 - rmse: 0.2123\n",
      "Epoch 607/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0227 - mse: 0.0457 - mae: 0.1493 - rmse: 0.2138\n",
      "Epoch 608/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0228 - mse: 0.0460 - mae: 0.1496 - rmse: 0.2145\n",
      "Epoch 609/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0228 - mse: 0.0460 - mae: 0.1498 - rmse: 0.2145\n",
      "Epoch 610/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0227 - mse: 0.0458 - mae: 0.1493 - rmse: 0.2140\n",
      "Epoch 611/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0225 - mse: 0.0454 - mae: 0.1491 - rmse: 0.2131\n",
      "Epoch 612/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0227 - mse: 0.0458 - mae: 0.1496 - rmse: 0.2140\n",
      "Epoch 613/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0226 - mse: 0.0456 - mae: 0.1494 - rmse: 0.2135\n",
      "Epoch 614/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0225 - mse: 0.0454 - mae: 0.1489 - rmse: 0.2130\n",
      "Epoch 615/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0225 - mse: 0.0454 - mae: 0.1490 - rmse: 0.2130\n",
      "Epoch 616/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0227 - mse: 0.0457 - mae: 0.1495 - rmse: 0.2138\n",
      "Epoch 617/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0227 - mse: 0.0458 - mae: 0.1495 - rmse: 0.2140\n",
      "Epoch 618/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0225 - mse: 0.0453 - mae: 0.1490 - rmse: 0.2129\n",
      "Epoch 619/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0224 - mse: 0.0451 - mae: 0.1489 - rmse: 0.2124\n",
      "Epoch 620/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0225 - mse: 0.0453 - mae: 0.1490 - rmse: 0.2129\n",
      "Epoch 621/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0225 - mse: 0.0454 - mae: 0.1489 - rmse: 0.2131\n",
      "Epoch 622/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0227 - mse: 0.0457 - mae: 0.1493 - rmse: 0.2137\n",
      "Epoch 623/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0225 - mse: 0.0453 - mae: 0.1488 - rmse: 0.2128\n",
      "Epoch 624/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0226 - mse: 0.0455 - mae: 0.1490 - rmse: 0.2132\n",
      "Epoch 625/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0226 - mse: 0.0454 - mae: 0.1491 - rmse: 0.2132\n",
      "Epoch 626/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0225 - mse: 0.0454 - mae: 0.1488 - rmse: 0.2131\n",
      "Epoch 627/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0224 - mse: 0.0452 - mae: 0.1487 - rmse: 0.2126\n",
      "Epoch 628/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0225 - mse: 0.0453 - mae: 0.1488 - rmse: 0.2128\n",
      "Epoch 629/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0223 - mse: 0.0450 - mae: 0.1485 - rmse: 0.2121\n",
      "Epoch 630/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0225 - mse: 0.0453 - mae: 0.1488 - rmse: 0.2129\n",
      "Epoch 631/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0224 - mse: 0.0452 - mae: 0.1486 - rmse: 0.2126\n",
      "Epoch 632/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0223 - mse: 0.0450 - mae: 0.1486 - rmse: 0.2121\n",
      "Epoch 633/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0223 - mse: 0.0450 - mae: 0.1487 - rmse: 0.2121\n",
      "Epoch 634/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0225 - mse: 0.0452 - mae: 0.1491 - rmse: 0.2127\n",
      "Epoch 635/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0224 - mse: 0.0451 - mae: 0.1487 - rmse: 0.2123\n",
      "Epoch 636/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0226 - mse: 0.0457 - mae: 0.1492 - rmse: 0.2137\n",
      "Epoch 637/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0226 - mse: 0.0456 - mae: 0.1492 - rmse: 0.2136\n",
      "Epoch 638/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0225 - mse: 0.0454 - mae: 0.1490 - rmse: 0.2130\n",
      "Epoch 639/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0225 - mse: 0.0454 - mae: 0.1489 - rmse: 0.2131\n",
      "Epoch 640/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0225 - mse: 0.0454 - mae: 0.1489 - rmse: 0.2130\n",
      "Epoch 641/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0226 - mse: 0.0456 - mae: 0.1491 - rmse: 0.2136\n",
      "Epoch 642/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0224 - mse: 0.0451 - mae: 0.1486 - rmse: 0.2123\n",
      "Epoch 643/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0224 - mse: 0.0452 - mae: 0.1487 - rmse: 0.2126\n",
      "Epoch 644/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0222 - mse: 0.0448 - mae: 0.1482 - rmse: 0.2118\n",
      "Epoch 645/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0225 - mse: 0.0453 - mae: 0.1486 - rmse: 0.2128\n",
      "Epoch 646/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0224 - mse: 0.0453 - mae: 0.1486 - rmse: 0.2127\n",
      "Epoch 647/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0223 - mse: 0.0449 - mae: 0.1483 - rmse: 0.2118\n",
      "Epoch 648/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0224 - mse: 0.0451 - mae: 0.1486 - rmse: 0.2124\n",
      "Epoch 649/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0224 - mse: 0.0452 - mae: 0.1487 - rmse: 0.2125\n",
      "Epoch 650/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0224 - mse: 0.0451 - mae: 0.1486 - rmse: 0.2124\n",
      "Epoch 651/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0223 - mse: 0.0449 - mae: 0.1484 - rmse: 0.2119\n",
      "Epoch 652/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0224 - mse: 0.0451 - mae: 0.1486 - rmse: 0.2123\n",
      "Epoch 653/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0223 - mse: 0.0450 - mae: 0.1483 - rmse: 0.2122\n",
      "Epoch 654/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0224 - mse: 0.0451 - mae: 0.1486 - rmse: 0.2123\n",
      "Epoch 655/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0223 - mse: 0.0450 - mae: 0.1483 - rmse: 0.2122\n",
      "Epoch 656/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0223 - mse: 0.0449 - mae: 0.1484 - rmse: 0.2119\n",
      "Epoch 657/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0222 - mse: 0.0448 - mae: 0.1481 - rmse: 0.2117\n",
      "Epoch 658/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0222 - mse: 0.0448 - mae: 0.1481 - rmse: 0.2117\n",
      "Epoch 659/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0223 - mse: 0.0448 - mae: 0.1483 - rmse: 0.2118\n",
      "Epoch 660/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0223 - mse: 0.0449 - mae: 0.1481 - rmse: 0.2118\n",
      "Epoch 661/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0224 - mse: 0.0452 - mae: 0.1486 - rmse: 0.2125\n",
      "Epoch 662/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0223 - mse: 0.0449 - mae: 0.1482 - rmse: 0.2119\n",
      "Epoch 663/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0223 - mse: 0.0449 - mae: 0.1482 - rmse: 0.2118\n",
      "Epoch 664/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0222 - mse: 0.0448 - mae: 0.1483 - rmse: 0.2116\n",
      "Epoch 665/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0224 - mse: 0.0452 - mae: 0.1485 - rmse: 0.2127\n",
      "Epoch 666/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0225 - mse: 0.0454 - mae: 0.1487 - rmse: 0.2131\n",
      "Epoch 667/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0224 - mse: 0.0451 - mae: 0.1484 - rmse: 0.2124\n",
      "Epoch 668/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0224 - mse: 0.0451 - mae: 0.1482 - rmse: 0.2124\n",
      "Epoch 669/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0221 - mse: 0.0445 - mae: 0.1478 - rmse: 0.2110\n",
      "Epoch 670/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0222 - mse: 0.0446 - mae: 0.1478 - rmse: 0.2113\n",
      "Epoch 671/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0222 - mse: 0.0446 - mae: 0.1479 - rmse: 0.2112\n",
      "Epoch 672/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0223 - mse: 0.0449 - mae: 0.1479 - rmse: 0.2119\n",
      "Epoch 673/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0224 - mse: 0.0451 - mae: 0.1486 - rmse: 0.2123\n",
      "Epoch 674/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0225 - mse: 0.0455 - mae: 0.1488 - rmse: 0.2133\n",
      "Epoch 675/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0222 - mse: 0.0448 - mae: 0.1479 - rmse: 0.2117\n",
      "Epoch 676/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0223 - mse: 0.0450 - mae: 0.1482 - rmse: 0.2122\n",
      "Epoch 677/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0223 - mse: 0.0450 - mae: 0.1483 - rmse: 0.2122\n",
      "Epoch 678/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0223 - mse: 0.0449 - mae: 0.1481 - rmse: 0.2119\n",
      "Epoch 679/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0221 - mse: 0.0446 - mae: 0.1477 - rmse: 0.2111\n",
      "Epoch 680/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0221 - mse: 0.0445 - mae: 0.1476 - rmse: 0.2111\n",
      "Epoch 681/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0224 - mse: 0.0452 - mae: 0.1483 - rmse: 0.2126\n",
      "Epoch 682/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0223 - mse: 0.0450 - mae: 0.1482 - rmse: 0.2121\n",
      "Epoch 683/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0223 - mse: 0.0449 - mae: 0.1481 - rmse: 0.2118\n",
      "Epoch 684/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0224 - mse: 0.0453 - mae: 0.1484 - rmse: 0.2128\n",
      "Epoch 685/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0222 - mse: 0.0448 - mae: 0.1480 - rmse: 0.2116\n",
      "Epoch 686/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0222 - mse: 0.0447 - mae: 0.1479 - rmse: 0.2115\n",
      "Epoch 687/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0220 - mse: 0.0444 - mae: 0.1474 - rmse: 0.2106\n",
      "Epoch 688/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0220 - mse: 0.0444 - mae: 0.1475 - rmse: 0.2108\n",
      "Epoch 689/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0223 - mse: 0.0449 - mae: 0.1480 - rmse: 0.2120\n",
      "Epoch 690/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0221 - mse: 0.0445 - mae: 0.1476 - rmse: 0.2108\n",
      "Epoch 691/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0222 - mse: 0.0447 - mae: 0.1477 - rmse: 0.2114\n",
      "Epoch 692/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0220 - mse: 0.0443 - mae: 0.1474 - rmse: 0.2105\n",
      "Epoch 693/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0222 - mse: 0.0448 - mae: 0.1480 - rmse: 0.2117\n",
      "Epoch 694/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0222 - mse: 0.0448 - mae: 0.1478 - rmse: 0.2115\n",
      "Epoch 695/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0220 - mse: 0.0442 - mae: 0.1472 - rmse: 0.2103\n",
      "Epoch 696/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0222 - mse: 0.0448 - mae: 0.1479 - rmse: 0.2118\n",
      "Epoch 697/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0221 - mse: 0.0446 - mae: 0.1477 - rmse: 0.2111\n",
      "Epoch 698/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0222 - mse: 0.0447 - mae: 0.1477 - rmse: 0.2115\n",
      "Epoch 699/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0223 - mse: 0.0450 - mae: 0.1480 - rmse: 0.2122\n",
      "Epoch 700/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0222 - mse: 0.0448 - mae: 0.1480 - rmse: 0.2116\n",
      "Epoch 701/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0222 - mse: 0.0448 - mae: 0.1478 - rmse: 0.2117\n",
      "Epoch 702/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0221 - mse: 0.0445 - mae: 0.1475 - rmse: 0.2110\n",
      "Epoch 703/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0222 - mse: 0.0447 - mae: 0.1478 - rmse: 0.2114\n",
      "Epoch 704/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0222 - mse: 0.0447 - mae: 0.1476 - rmse: 0.2114\n",
      "Epoch 705/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0219 - mse: 0.0442 - mae: 0.1472 - rmse: 0.2101\n",
      "Epoch 706/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0223 - mse: 0.0449 - mae: 0.1479 - rmse: 0.2119\n",
      "Epoch 707/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0222 - mse: 0.0448 - mae: 0.1479 - rmse: 0.2117\n",
      "Epoch 708/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0224 - mse: 0.0451 - mae: 0.1481 - rmse: 0.2124\n",
      "Epoch 709/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0223 - mse: 0.0449 - mae: 0.1480 - rmse: 0.2120\n",
      "Epoch 710/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0220 - mse: 0.0444 - mae: 0.1474 - rmse: 0.2106\n",
      "Epoch 711/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0221 - mse: 0.0446 - mae: 0.1478 - rmse: 0.2112\n",
      "Epoch 712/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0222 - mse: 0.0447 - mae: 0.1476 - rmse: 0.2115\n",
      "Epoch 713/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0220 - mse: 0.0442 - mae: 0.1470 - rmse: 0.2103\n",
      "Epoch 714/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0224 - mse: 0.0451 - mae: 0.1481 - rmse: 0.2124\n",
      "Epoch 715/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0220 - mse: 0.0443 - mae: 0.1473 - rmse: 0.2106\n",
      "Epoch 716/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0223 - mse: 0.0449 - mae: 0.1480 - rmse: 0.2119\n",
      "Epoch 717/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0221 - mse: 0.0446 - mae: 0.1476 - rmse: 0.2112\n",
      "Epoch 718/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0223 - mse: 0.0450 - mae: 0.1479 - rmse: 0.2121\n",
      "Epoch 719/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0221 - mse: 0.0445 - mae: 0.1472 - rmse: 0.2108\n",
      "Epoch 720/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0221 - mse: 0.0446 - mae: 0.1471 - rmse: 0.2112\n",
      "Epoch 721/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0218 - mse: 0.0440 - mae: 0.1466 - rmse: 0.2098\n",
      "Epoch 722/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0220 - mse: 0.0444 - mae: 0.1471 - rmse: 0.2106\n",
      "Epoch 723/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0222 - mse: 0.0447 - mae: 0.1475 - rmse: 0.2115\n",
      "Epoch 724/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0222 - mse: 0.0448 - mae: 0.1478 - rmse: 0.2115\n",
      "Epoch 725/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0220 - mse: 0.0443 - mae: 0.1472 - rmse: 0.2105\n",
      "Epoch 726/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0219 - mse: 0.0441 - mae: 0.1470 - rmse: 0.2099\n",
      "Epoch 727/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0220 - mse: 0.0443 - mae: 0.1470 - rmse: 0.2105\n",
      "Epoch 728/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0220 - mse: 0.0443 - mae: 0.1470 - rmse: 0.2105\n",
      "Epoch 729/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0220 - mse: 0.0443 - mae: 0.1469 - rmse: 0.2105\n",
      "Epoch 730/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0221 - mse: 0.0445 - mae: 0.1473 - rmse: 0.2109\n",
      "Epoch 731/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0222 - mse: 0.0447 - mae: 0.1474 - rmse: 0.2115\n",
      "Epoch 732/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0222 - mse: 0.0448 - mae: 0.1476 - rmse: 0.2116\n",
      "Epoch 733/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0220 - mse: 0.0443 - mae: 0.1470 - rmse: 0.2106\n",
      "Epoch 734/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0219 - mse: 0.0441 - mae: 0.1469 - rmse: 0.2101\n",
      "Epoch 735/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0220 - mse: 0.0443 - mae: 0.1471 - rmse: 0.2104\n",
      "Epoch 736/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0220 - mse: 0.0443 - mae: 0.1470 - rmse: 0.2104\n",
      "Epoch 737/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0221 - mse: 0.0444 - mae: 0.1473 - rmse: 0.2108\n",
      "Epoch 738/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0220 - mse: 0.0444 - mae: 0.1470 - rmse: 0.2106\n",
      "Epoch 739/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0221 - mse: 0.0445 - mae: 0.1474 - rmse: 0.2111\n",
      "Epoch 740/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0220 - mse: 0.0442 - mae: 0.1470 - rmse: 0.2103\n",
      "Epoch 741/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0219 - mse: 0.0442 - mae: 0.1468 - rmse: 0.2102\n",
      "Epoch 742/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0220 - mse: 0.0444 - mae: 0.1470 - rmse: 0.2107\n",
      "Epoch 743/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0220 - mse: 0.0444 - mae: 0.1470 - rmse: 0.2107\n",
      "Epoch 744/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0219 - mse: 0.0442 - mae: 0.1471 - rmse: 0.2102\n",
      "Epoch 745/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0220 - mse: 0.0444 - mae: 0.1471 - rmse: 0.2107\n",
      "Epoch 746/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0222 - mse: 0.0447 - mae: 0.1474 - rmse: 0.2114\n",
      "Epoch 747/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0219 - mse: 0.0442 - mae: 0.1469 - rmse: 0.2102\n",
      "Epoch 748/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0221 - mse: 0.0446 - mae: 0.1471 - rmse: 0.2111\n",
      "Epoch 749/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0221 - mse: 0.0446 - mae: 0.1472 - rmse: 0.2112\n",
      "Epoch 750/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0222 - mse: 0.0447 - mae: 0.1474 - rmse: 0.2113\n",
      "Epoch 751/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0220 - mse: 0.0443 - mae: 0.1468 - rmse: 0.2106\n",
      "Epoch 752/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0219 - mse: 0.0441 - mae: 0.1466 - rmse: 0.2100\n",
      "Epoch 753/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0221 - mse: 0.0448 - mae: 0.1472 - rmse: 0.2116\n",
      "Epoch 754/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0218 - mse: 0.0439 - mae: 0.1467 - rmse: 0.2096\n",
      "Epoch 755/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0221 - mse: 0.0445 - mae: 0.1471 - rmse: 0.2108\n",
      "Epoch 756/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0219 - mse: 0.0441 - mae: 0.1466 - rmse: 0.2100\n",
      "Epoch 757/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0221 - mse: 0.0446 - mae: 0.1472 - rmse: 0.2111\n",
      "Epoch 758/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0218 - mse: 0.0439 - mae: 0.1466 - rmse: 0.2095\n",
      "Epoch 759/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0221 - mse: 0.0445 - mae: 0.1471 - rmse: 0.2109\n",
      "Epoch 760/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0220 - mse: 0.0443 - mae: 0.1469 - rmse: 0.2104\n",
      "Epoch 761/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0220 - mse: 0.0443 - mae: 0.1469 - rmse: 0.2104\n",
      "Epoch 762/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0219 - mse: 0.0442 - mae: 0.1469 - rmse: 0.2102\n",
      "Epoch 763/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0219 - mse: 0.0442 - mae: 0.1467 - rmse: 0.2103\n",
      "Epoch 764/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0221 - mse: 0.0445 - mae: 0.1469 - rmse: 0.2109\n",
      "Epoch 765/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0220 - mse: 0.0444 - mae: 0.1469 - rmse: 0.2108\n",
      "Epoch 766/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0220 - mse: 0.0442 - mae: 0.1468 - rmse: 0.2103\n",
      "Epoch 767/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0218 - mse: 0.0440 - mae: 0.1464 - rmse: 0.2097\n",
      "Epoch 768/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0220 - mse: 0.0444 - mae: 0.1468 - rmse: 0.2107\n",
      "Epoch 769/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0221 - mse: 0.0445 - mae: 0.1470 - rmse: 0.2109\n",
      "Epoch 770/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0220 - mse: 0.0444 - mae: 0.1469 - rmse: 0.2107\n",
      "Epoch 771/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0221 - mse: 0.0446 - mae: 0.1472 - rmse: 0.2112\n",
      "Epoch 772/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0218 - mse: 0.0439 - mae: 0.1463 - rmse: 0.2096\n",
      "Epoch 773/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0220 - mse: 0.0443 - mae: 0.1467 - rmse: 0.2105\n",
      "Epoch 774/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0219 - mse: 0.0441 - mae: 0.1466 - rmse: 0.2100\n",
      "Epoch 775/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0217 - mse: 0.0438 - mae: 0.1461 - rmse: 0.2093\n",
      "Epoch 776/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0218 - mse: 0.0439 - mae: 0.1465 - rmse: 0.2096\n",
      "Epoch 777/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0219 - mse: 0.0440 - mae: 0.1463 - rmse: 0.2098\n",
      "Epoch 778/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0218 - mse: 0.0438 - mae: 0.1463 - rmse: 0.2094\n",
      "Epoch 779/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0218 - mse: 0.0439 - mae: 0.1463 - rmse: 0.2096\n",
      "Epoch 780/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0218 - mse: 0.0439 - mae: 0.1463 - rmse: 0.2095\n",
      "Epoch 781/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0218 - mse: 0.0438 - mae: 0.1461 - rmse: 0.2094\n",
      "Epoch 782/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0220 - mse: 0.0443 - mae: 0.1468 - rmse: 0.2104\n",
      "Epoch 783/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0217 - mse: 0.0438 - mae: 0.1460 - rmse: 0.2094\n",
      "Epoch 784/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0220 - mse: 0.0443 - mae: 0.1466 - rmse: 0.2105\n",
      "Epoch 785/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0219 - mse: 0.0441 - mae: 0.1465 - rmse: 0.2100\n",
      "Epoch 786/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0218 - mse: 0.0438 - mae: 0.1462 - rmse: 0.2094\n",
      "Epoch 787/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0219 - mse: 0.0442 - mae: 0.1467 - rmse: 0.2102\n",
      "Epoch 788/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0221 - mse: 0.0447 - mae: 0.1470 - rmse: 0.2113\n",
      "Epoch 789/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0219 - mse: 0.0442 - mae: 0.1465 - rmse: 0.2101\n",
      "Epoch 790/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0219 - mse: 0.0441 - mae: 0.1465 - rmse: 0.2101\n",
      "Epoch 791/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0217 - mse: 0.0437 - mae: 0.1461 - rmse: 0.2090\n",
      "Epoch 792/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0219 - mse: 0.0442 - mae: 0.1466 - rmse: 0.2103\n",
      "Epoch 793/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0219 - mse: 0.0440 - mae: 0.1465 - rmse: 0.2098\n",
      "Epoch 794/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0221 - mse: 0.0445 - mae: 0.1469 - rmse: 0.2110\n",
      "Epoch 795/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0217 - mse: 0.0438 - mae: 0.1462 - rmse: 0.2094\n",
      "Epoch 796/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0219 - mse: 0.0441 - mae: 0.1465 - rmse: 0.2101\n",
      "Epoch 797/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0219 - mse: 0.0441 - mae: 0.1466 - rmse: 0.2100\n",
      "Epoch 798/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0218 - mse: 0.0439 - mae: 0.1463 - rmse: 0.2095\n",
      "Epoch 799/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0217 - mse: 0.0437 - mae: 0.1461 - rmse: 0.2091\n",
      "Epoch 800/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0218 - mse: 0.0439 - mae: 0.1462 - rmse: 0.2094\n",
      "Epoch 801/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0218 - mse: 0.0439 - mae: 0.1463 - rmse: 0.2094\n",
      "Epoch 802/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0217 - mse: 0.0436 - mae: 0.1461 - rmse: 0.2088\n",
      "Epoch 803/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0217 - mse: 0.0437 - mae: 0.1458 - rmse: 0.2090\n",
      "Epoch 804/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0219 - mse: 0.0441 - mae: 0.1465 - rmse: 0.2101\n",
      "Epoch 805/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0217 - mse: 0.0438 - mae: 0.1460 - rmse: 0.2093\n",
      "Epoch 806/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0217 - mse: 0.0437 - mae: 0.1460 - rmse: 0.2091\n",
      "Epoch 807/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0217 - mse: 0.0437 - mae: 0.1461 - rmse: 0.2091\n",
      "Epoch 808/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0217 - mse: 0.0438 - mae: 0.1461 - rmse: 0.2093\n",
      "Epoch 809/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0219 - mse: 0.0441 - mae: 0.1465 - rmse: 0.2100\n",
      "Epoch 810/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0216 - mse: 0.0436 - mae: 0.1457 - rmse: 0.2087\n",
      "Epoch 811/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0217 - mse: 0.0438 - mae: 0.1461 - rmse: 0.2093\n",
      "Epoch 812/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0218 - mse: 0.0439 - mae: 0.1460 - rmse: 0.2095\n",
      "Epoch 813/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0218 - mse: 0.0439 - mae: 0.1462 - rmse: 0.2096\n",
      "Epoch 814/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0216 - mse: 0.0436 - mae: 0.1457 - rmse: 0.2088\n",
      "Epoch 815/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0216 - mse: 0.0434 - mae: 0.1455 - rmse: 0.2084\n",
      "Epoch 816/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0216 - mse: 0.0436 - mae: 0.1457 - rmse: 0.2087\n",
      "Epoch 817/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0217 - mse: 0.0438 - mae: 0.1460 - rmse: 0.2093\n",
      "Epoch 818/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0217 - mse: 0.0437 - mae: 0.1456 - rmse: 0.2091\n",
      "Epoch 819/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0217 - mse: 0.0437 - mae: 0.1459 - rmse: 0.2091\n",
      "Epoch 820/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0218 - mse: 0.0438 - mae: 0.1461 - rmse: 0.2094\n",
      "Epoch 821/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0216 - mse: 0.0436 - mae: 0.1457 - rmse: 0.2087\n",
      "Epoch 822/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0218 - mse: 0.0439 - mae: 0.1461 - rmse: 0.2096\n",
      "Epoch 823/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0217 - mse: 0.0437 - mae: 0.1461 - rmse: 0.2091\n",
      "Epoch 824/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0218 - mse: 0.0440 - mae: 0.1462 - rmse: 0.2098\n",
      "Epoch 825/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0218 - mse: 0.0440 - mae: 0.1461 - rmse: 0.2097\n",
      "Epoch 826/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0217 - mse: 0.0437 - mae: 0.1456 - rmse: 0.2090\n",
      "Epoch 827/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0217 - mse: 0.0438 - mae: 0.1459 - rmse: 0.2093\n",
      "Epoch 828/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0217 - mse: 0.0437 - mae: 0.1456 - rmse: 0.2090\n",
      "Epoch 829/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0217 - mse: 0.0436 - mae: 0.1457 - rmse: 0.2088\n",
      "Epoch 830/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0216 - mse: 0.0434 - mae: 0.1454 - rmse: 0.2084\n",
      "Epoch 831/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0216 - mse: 0.0434 - mae: 0.1455 - rmse: 0.2084\n",
      "Epoch 832/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0215 - mse: 0.0434 - mae: 0.1454 - rmse: 0.2083\n",
      "Epoch 833/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0216 - mse: 0.0436 - mae: 0.1454 - rmse: 0.2087\n",
      "Epoch 834/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0216 - mse: 0.0435 - mae: 0.1456 - rmse: 0.2085\n",
      "Epoch 835/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0215 - mse: 0.0434 - mae: 0.1453 - rmse: 0.2083\n",
      "Epoch 836/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0218 - mse: 0.0440 - mae: 0.1460 - rmse: 0.2098\n",
      "Epoch 837/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0217 - mse: 0.0436 - mae: 0.1457 - rmse: 0.2089\n",
      "Epoch 838/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0216 - mse: 0.0436 - mae: 0.1458 - rmse: 0.2088\n",
      "Epoch 839/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0217 - mse: 0.0437 - mae: 0.1459 - rmse: 0.2091\n",
      "Epoch 840/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0216 - mse: 0.0436 - mae: 0.1457 - rmse: 0.2088\n",
      "Epoch 841/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0216 - mse: 0.0434 - mae: 0.1453 - rmse: 0.2083\n",
      "Epoch 842/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0215 - mse: 0.0433 - mae: 0.1453 - rmse: 0.2081\n",
      "Epoch 843/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0216 - mse: 0.0436 - mae: 0.1456 - rmse: 0.2087\n",
      "Epoch 844/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0216 - mse: 0.0436 - mae: 0.1454 - rmse: 0.2087\n",
      "Epoch 845/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0216 - mse: 0.0436 - mae: 0.1456 - rmse: 0.2089\n",
      "Epoch 846/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0215 - mse: 0.0432 - mae: 0.1451 - rmse: 0.2080\n",
      "Epoch 847/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0217 - mse: 0.0437 - mae: 0.1455 - rmse: 0.2089\n",
      "Epoch 848/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0215 - mse: 0.0433 - mae: 0.1450 - rmse: 0.2081\n",
      "Epoch 849/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0217 - mse: 0.0438 - mae: 0.1459 - rmse: 0.2093\n",
      "Epoch 850/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0216 - mse: 0.0436 - mae: 0.1454 - rmse: 0.2088\n",
      "Epoch 851/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0216 - mse: 0.0435 - mae: 0.1455 - rmse: 0.2085\n",
      "Epoch 852/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0215 - mse: 0.0434 - mae: 0.1452 - rmse: 0.2082\n",
      "Epoch 853/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0214 - mse: 0.0430 - mae: 0.1450 - rmse: 0.2073\n",
      "Epoch 854/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0216 - mse: 0.0436 - mae: 0.1457 - rmse: 0.2088\n",
      "Epoch 855/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0216 - mse: 0.0436 - mae: 0.1455 - rmse: 0.2088\n",
      "Epoch 856/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0216 - mse: 0.0435 - mae: 0.1455 - rmse: 0.2085\n",
      "Epoch 857/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0216 - mse: 0.0436 - mae: 0.1454 - rmse: 0.2088\n",
      "Epoch 858/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0215 - mse: 0.0433 - mae: 0.1452 - rmse: 0.2082\n",
      "Epoch 859/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0215 - mse: 0.0434 - mae: 0.1454 - rmse: 0.2083\n",
      "Epoch 860/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0217 - mse: 0.0437 - mae: 0.1456 - rmse: 0.2091\n",
      "Epoch 861/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0216 - mse: 0.0436 - mae: 0.1454 - rmse: 0.2087\n",
      "Epoch 862/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0214 - mse: 0.0430 - mae: 0.1450 - rmse: 0.2075\n",
      "Epoch 863/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0217 - mse: 0.0438 - mae: 0.1456 - rmse: 0.2092\n",
      "Epoch 864/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0216 - mse: 0.0435 - mae: 0.1454 - rmse: 0.2086\n",
      "Epoch 865/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0214 - mse: 0.0431 - mae: 0.1449 - rmse: 0.2077\n",
      "Epoch 866/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0215 - mse: 0.0433 - mae: 0.1451 - rmse: 0.2081\n",
      "Epoch 867/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0215 - mse: 0.0434 - mae: 0.1451 - rmse: 0.2083\n",
      "Epoch 868/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0216 - mse: 0.0436 - mae: 0.1454 - rmse: 0.2089\n",
      "Epoch 869/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0216 - mse: 0.0435 - mae: 0.1454 - rmse: 0.2087\n",
      "Epoch 870/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0215 - mse: 0.0433 - mae: 0.1450 - rmse: 0.2080\n",
      "Epoch 871/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0214 - mse: 0.0431 - mae: 0.1447 - rmse: 0.2076\n",
      "Epoch 872/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0215 - mse: 0.0432 - mae: 0.1450 - rmse: 0.2079\n",
      "Epoch 873/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0215 - mse: 0.0433 - mae: 0.1450 - rmse: 0.2080\n",
      "Epoch 874/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0215 - mse: 0.0432 - mae: 0.1450 - rmse: 0.2079\n",
      "Epoch 875/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0214 - mse: 0.0432 - mae: 0.1450 - rmse: 0.2078\n",
      "Epoch 876/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0215 - mse: 0.0433 - mae: 0.1452 - rmse: 0.2082\n",
      "Epoch 877/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0215 - mse: 0.0434 - mae: 0.1452 - rmse: 0.2083\n",
      "Epoch 878/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0214 - mse: 0.0431 - mae: 0.1448 - rmse: 0.2075\n",
      "Epoch 879/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0215 - mse: 0.0433 - mae: 0.1451 - rmse: 0.2080\n",
      "Epoch 880/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0214 - mse: 0.0431 - mae: 0.1449 - rmse: 0.2077\n",
      "Epoch 881/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0216 - mse: 0.0437 - mae: 0.1453 - rmse: 0.2091\n",
      "Epoch 882/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0216 - mse: 0.0435 - mae: 0.1451 - rmse: 0.2086\n",
      "Epoch 883/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0217 - mse: 0.0437 - mae: 0.1454 - rmse: 0.2091\n",
      "Epoch 884/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0214 - mse: 0.0431 - mae: 0.1449 - rmse: 0.2077\n",
      "Epoch 885/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0213 - mse: 0.0430 - mae: 0.1446 - rmse: 0.2073\n",
      "Epoch 886/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0215 - mse: 0.0433 - mae: 0.1452 - rmse: 0.2082\n",
      "Epoch 887/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0217 - mse: 0.0438 - mae: 0.1454 - rmse: 0.2092\n",
      "Epoch 888/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0215 - mse: 0.0433 - mae: 0.1450 - rmse: 0.2081\n",
      "Epoch 889/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0214 - mse: 0.0431 - mae: 0.1448 - rmse: 0.2076\n",
      "Epoch 890/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0216 - mse: 0.0435 - mae: 0.1451 - rmse: 0.2085\n",
      "Epoch 891/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0215 - mse: 0.0434 - mae: 0.1451 - rmse: 0.2083\n",
      "Epoch 892/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0215 - mse: 0.0433 - mae: 0.1449 - rmse: 0.2081\n",
      "Epoch 893/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0214 - mse: 0.0430 - mae: 0.1450 - rmse: 0.2074\n",
      "Epoch 894/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0216 - mse: 0.0434 - mae: 0.1453 - rmse: 0.2084\n",
      "Epoch 895/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0216 - mse: 0.0435 - mae: 0.1451 - rmse: 0.2086\n",
      "Epoch 896/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0216 - mse: 0.0434 - mae: 0.1452 - rmse: 0.2084\n",
      "Epoch 897/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0214 - mse: 0.0430 - mae: 0.1448 - rmse: 0.2074\n",
      "Epoch 898/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0214 - mse: 0.0431 - mae: 0.1447 - rmse: 0.2076\n",
      "Epoch 899/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0215 - mse: 0.0433 - mae: 0.1451 - rmse: 0.2080\n",
      "Epoch 900/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0213 - mse: 0.0430 - mae: 0.1446 - rmse: 0.2073\n",
      "Epoch 901/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0214 - mse: 0.0431 - mae: 0.1447 - rmse: 0.2075\n",
      "Epoch 902/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0214 - mse: 0.0431 - mae: 0.1447 - rmse: 0.2076\n",
      "Epoch 903/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0214 - mse: 0.0430 - mae: 0.1447 - rmse: 0.2073\n",
      "Epoch 904/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0215 - mse: 0.0433 - mae: 0.1450 - rmse: 0.2080\n",
      "Epoch 905/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0214 - mse: 0.0430 - mae: 0.1448 - rmse: 0.2074\n",
      "Epoch 906/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0214 - mse: 0.0431 - mae: 0.1448 - rmse: 0.2075\n",
      "Epoch 907/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0214 - mse: 0.0432 - mae: 0.1448 - rmse: 0.2078\n",
      "Epoch 908/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0214 - mse: 0.0431 - mae: 0.1447 - rmse: 0.2076\n",
      "Epoch 909/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0214 - mse: 0.0431 - mae: 0.1449 - rmse: 0.2077\n",
      "Epoch 910/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0215 - mse: 0.0432 - mae: 0.1449 - rmse: 0.2079\n",
      "Epoch 911/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0214 - mse: 0.0432 - mae: 0.1447 - rmse: 0.2079\n",
      "Epoch 912/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0214 - mse: 0.0431 - mae: 0.1448 - rmse: 0.2077\n",
      "Epoch 913/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0214 - mse: 0.0431 - mae: 0.1446 - rmse: 0.2077\n",
      "Epoch 914/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0213 - mse: 0.0429 - mae: 0.1446 - rmse: 0.2072\n",
      "Epoch 915/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0215 - mse: 0.0432 - mae: 0.1447 - rmse: 0.2079\n",
      "Epoch 916/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0215 - mse: 0.0432 - mae: 0.1449 - rmse: 0.2079\n",
      "Epoch 917/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0213 - mse: 0.0428 - mae: 0.1444 - rmse: 0.2069\n",
      "Epoch 918/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0215 - mse: 0.0433 - mae: 0.1448 - rmse: 0.2081\n",
      "Epoch 919/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0214 - mse: 0.0431 - mae: 0.1446 - rmse: 0.2077\n",
      "Epoch 920/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0214 - mse: 0.0430 - mae: 0.1447 - rmse: 0.2074\n",
      "Epoch 921/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0213 - mse: 0.0430 - mae: 0.1444 - rmse: 0.2074\n",
      "Epoch 922/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0213 - mse: 0.0430 - mae: 0.1443 - rmse: 0.2073\n",
      "Epoch 923/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0213 - mse: 0.0429 - mae: 0.1444 - rmse: 0.2071\n",
      "Epoch 924/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0215 - mse: 0.0432 - mae: 0.1449 - rmse: 0.2078\n",
      "Epoch 925/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0212 - mse: 0.0427 - mae: 0.1441 - rmse: 0.2067\n",
      "Epoch 926/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0212 - mse: 0.0427 - mae: 0.1442 - rmse: 0.2066\n",
      "Epoch 927/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0215 - mse: 0.0433 - mae: 0.1447 - rmse: 0.2080\n",
      "Epoch 928/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0214 - mse: 0.0431 - mae: 0.1446 - rmse: 0.2077\n",
      "Epoch 929/950\n",
      "786/786 [==============================] - 15s 18ms/step - loss: 0.0214 - mse: 0.0431 - mae: 0.1449 - rmse: 0.2075\n",
      "Epoch 930/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0214 - mse: 0.0432 - mae: 0.1448 - rmse: 0.2079\n",
      "Epoch 931/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0212 - mse: 0.0428 - mae: 0.1442 - rmse: 0.2068\n",
      "Epoch 932/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0213 - mse: 0.0430 - mae: 0.1444 - rmse: 0.2073\n",
      "Epoch 933/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0214 - mse: 0.0432 - mae: 0.1446 - rmse: 0.2079\n",
      "Epoch 934/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0214 - mse: 0.0432 - mae: 0.1446 - rmse: 0.2078\n",
      "Epoch 935/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0214 - mse: 0.0430 - mae: 0.1445 - rmse: 0.2074\n",
      "Epoch 936/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0214 - mse: 0.0430 - mae: 0.1447 - rmse: 0.2074\n",
      "Epoch 937/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0213 - mse: 0.0430 - mae: 0.1445 - rmse: 0.2074\n",
      "Epoch 938/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0213 - mse: 0.0430 - mae: 0.1444 - rmse: 0.2074\n",
      "Epoch 939/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0214 - mse: 0.0431 - mae: 0.1446 - rmse: 0.2076\n",
      "Epoch 940/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0213 - mse: 0.0430 - mae: 0.1446 - rmse: 0.2073\n",
      "Epoch 941/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0212 - mse: 0.0427 - mae: 0.1441 - rmse: 0.2067\n",
      "Epoch 942/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0213 - mse: 0.0430 - mae: 0.1444 - rmse: 0.2073\n",
      "Epoch 943/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0214 - mse: 0.0430 - mae: 0.1445 - rmse: 0.2074\n",
      "Epoch 944/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0214 - mse: 0.0431 - mae: 0.1445 - rmse: 0.2077\n",
      "Epoch 945/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0212 - mse: 0.0427 - mae: 0.1441 - rmse: 0.2066\n",
      "Epoch 946/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0212 - mse: 0.0428 - mae: 0.1441 - rmse: 0.2069\n",
      "Epoch 947/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0214 - mse: 0.0430 - mae: 0.1446 - rmse: 0.2074\n",
      "Epoch 948/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0212 - mse: 0.0428 - mae: 0.1443 - rmse: 0.2068\n",
      "Epoch 949/950\n",
      "786/786 [==============================] - 15s 19ms/step - loss: 0.0213 - mse: 0.0430 - mae: 0.1443 - rmse: 0.2073\n",
      "Epoch 950/950\n",
      "786/786 [==============================] - 14s 18ms/step - loss: 0.0213 - mse: 0.0429 - mae: 0.1441 - rmse: 0.2071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/NNmodel/1DCNN_final_architecture/fftAndOffshoreTides/93ks/bestModel_93ks_nonVal.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/NNmodel/1DCNN_final_architecture/fftAndOffshoreTides/93ks/bestModel_93ks_nonVal.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 3.845 hrs\n",
      "434/434 [==============================] - 3s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.mkdir(pathOut)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "#### Define model\n",
    "model = Sequential([\n",
    "                Masking(-9999, input_shape=(X_train.shape[1:])),\n",
    "                Conv1D(16, kernel_size=3, activation='relu'),\n",
    "                BatchNormalization(),\n",
    "                MaxPooling1D(pool_size=2),\n",
    "                Conv1D(32, kernel_size=3, activation='relu'),\n",
    "                BatchNormalization(),\n",
    "                MaxPooling1D(pool_size=2),\n",
    "                Conv1D(64, kernel_size=3, activation='relu'),\n",
    "                BatchNormalization(),\n",
    "                MaxPooling1D(pool_size=2),\n",
    "                Flatten(),\n",
    "                Dense(64, activation='relu'),\n",
    "                Dropout(0.2),\n",
    "                Dense(32, activation='relu'),\n",
    "                Dropout(0.2),\n",
    "                Dense(9, activation='relu'),\n",
    "            ])\n",
    "\n",
    "optimizer = RMSprop(learning_rate = 1e-4)\n",
    "model.compile(optimizer=optimizer, loss=tf.keras.losses.Huber(), \n",
    "                metrics=['mse', 'mae', tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "model.summary()\n",
    "\n",
    "#### train the model\n",
    "t0 = time.time()\n",
    "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1)\n",
    "model.save(pathOut / f'bestModel_{modelID}_nonVal.tf')\n",
    "print(f'Training time: {(time.time() - t0)/3600:0.3f} hrs')\n",
    "\n",
    "####  predictions\n",
    "predictions = model.predict(X_test)\n",
    "dfPred = pd.DataFrame(predictions, columns = [f'{x}_pred' for x in NOAAstations])\n",
    "dfTest = pd.DataFrame(y_test.reshape(y_test.shape[:2]), columns = NOAAstations)\n",
    "dfAll = pd.concat([dfTest, dfPred], axis = 1)\n",
    "dfAll.to_csv(pathOut/f'predTestSet_{modelID}.csv')\n",
    "\n",
    "# for i in range(6):\n",
    "#     fig, ax = plt.subplots(figsize = (4,4))\n",
    "#     sns.regplot(x = dfTest.iloc[:, i], y = dfPred.iloc[:, i], ax = ax, fit_reg = False)\n",
    "#     ax.plot(np.arange(0, 5, 0.5), np.arange(0, 5, 0.5), ls = '--', c = 'k')\n",
    "#     ax.set_title(f'{NOAAstations[i]}')\n",
    "#     fig.savefig(pathOut/f'predTestSet_{modelID}_{NOAAstations[i]}.png',\n",
    "#                 dpi = 100, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
